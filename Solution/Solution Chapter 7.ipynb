{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe834123-f027-457e-a398-31c48d73cece",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.1.\n",
    "\n",
    "Consider the setting of Knaster-Tarski fixed point theorem, and suppose that in addition that $v_1\\neq v_2$.\n",
    "\n",
    "Show that there exists an order-preserving self-map on $V$ with a continuum of fixed point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6205cd8-79fb-4e26-9906-78e02f561962",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Let $T:V\\mapsto V$ and \n",
    "\n",
    "$$\n",
    "Tv_i = v_i \\,\\,\\,\\forall v_i\\in V\n",
    "$$\n",
    "\n",
    "Then, we have, for $v_i\\le v_j$, \n",
    "\n",
    "$$\n",
    "v_i\\le v_j \\implies Tv_i\\le Tv_j\n",
    "$$\n",
    "\n",
    "hence, $T$ is order-preserving, and all elements in $V$ is a fixed point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26705bf8-dcc9-493c-99a7-2cc49f7bbb82",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.2.\n",
    "\n",
    "Prove that the map $g$ and set $U$ defined in the discussion of the Solow-Swan model above proposition 7.1.2. satisfies the conditions of proposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d51e4e0-8dcf-4aa1-acf0-16858b08e815",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We need to check \n",
    "\n",
    "- [x] $g$ is an increasing, concave, self-map\n",
    "- [x] $U=(0,\\infty)$\n",
    "- [x] For every $x\\in U$, there exists $a, b$ such that $a\\le x\\le b$ and $a<g(a), g(b)\\le b$.\n",
    "\n",
    "In the Solow-Swan model, we have, $g$ is defined as follows:\n",
    "\n",
    "$$\n",
    "g(k) = sf(k) + (1-\\delta)k\n",
    "$$\n",
    "\n",
    ", $f$ is increasing and vconcave, hence $g$ is also concave and increasing. For any positive $k$, $g(k)$ is positive, hence it is a self map on $U=(0,\\infty)$.\n",
    "\n",
    "And we can always pick $a,b$ such that $a\\le k*, b\\ge k^*$ that satifies the above conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b273b0d-52c6-4972-98e4-48aa9548edd4",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.3. \n",
    "\n",
    "Show that the condition $a<g(a)$ in Proposition 7.1.2. cannot be dropped without weakening the conclusioin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd269218-a960-414c-97ad-3cb5f565eee7",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "If we drop the $a<g(a)$ condition, we will not necessarily get a strict concave function. Hence, we cannot ensure there is a unique fixed point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb8a70-8fb3-4d2a-a6da-15c7201311c5",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.4.\n",
    "\n",
    "Dropping the Cobb-Douglas specification on production, suppose \n",
    "\n",
    "$$\n",
    "g(k)=sf(k)+(1-\\delta)k \n",
    "$$\n",
    "\n",
    "where $0<s,\\delta<1$ and $f$ is strictly positive increasing concave production function on $U=(0,\\infty)$ satisfying the **Inada condition**.\n",
    "\n",
    "$$\n",
    "f'(k)\\to \\infty, f'(k)\\to 0, k\\to \\infty\n",
    "$$\n",
    "\n",
    "Use proposition 7.1.2., to prove that $g$ is globally stable on $U$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddcdf0-e6b6-41ac-b403-ceae22d6b9b5",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "To prove $g$ is globally stable on $U$, we need to show that it satisfies the three conditions in proposition 7.1.2.\n",
    "\n",
    "We need to check:\n",
    "\n",
    "- [x] $g$ is a self-map, increasing, concave \n",
    "\n",
    "- [x] $U=(0,\\infty)$\n",
    "\n",
    "- [x] $\\forall x\\in U$,  there exists $a\\le x\\le b$ such that $a<g(a), g(b)\\le b$.\n",
    "\n",
    "\n",
    "The first condition is satisfied by the Inada condition.\n",
    "\n",
    "The second is given.\n",
    "\n",
    "The third has similar reasoning as in EXERCISE 7.1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62841ba0-b73b-4236-86ea-94c154dd1804",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.5.\n",
    "\n",
    "Fajgelbaum et al study a law of motion for aggregate uncertainty given by\n",
    "\n",
    "$$\n",
    "s_{t+1} = g(s_t), g(s) = \\rho^2\\left[\\frac{1}{s}+a^2 \\frac{1}{\\eta}\\right]^{-1}+\\gamma\n",
    "$$\n",
    "\n",
    "Let $\\alpha,\\eta, \\gamma$ be positive constants and assume that $0<\\rho<1$. Prove that $g$ is globally stable on $M=(0,\\infty)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbff76-dab0-45a7-b227-11712d0fcf2b",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.6.\n",
    "\n",
    "Let $F$ and $G$ be self-maps on convex $D\\subset\\mathbb{R}^n$.\n",
    "\n",
    "Show that $T=F\\circ G$ is concave whenever $F$ and $G$ are order-preserving and concave on $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a94a7-e78f-40fa-90f6-315ebf1a6e69",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have $F,G$ are concave, by definition, there exists $\\lambda \\in (0,1)$ such that, for any $x,y\\in D$,\n",
    "\n",
    "$$\n",
    "\\lambda F(x) +(1-\\lambda)F(y) \\le F(\\lambda x+(1-\\lambda) y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda G(x) +(1-\\lambda)G(y) \\le G(\\lambda x+(1-\\lambda) y)\n",
    "$$\n",
    "\n",
    "Since $F,G$ are self-maps, we have, $G(x),G(y)\\in D$. Then, we have,\n",
    "\n",
    "$$\n",
    "\\lambda T(x)+(1-\\lambda) T(y) = \\lambda F(G(x)) + (1-\\lambda)F(G(y)) \\le F(\\lambda G(x) + (1-\\lambda)G(y))\\le F(G(\\lambda x + (1-\\lambda)y))  = T(\\lambda x+(1-\\lambda)y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec359ca-71c9-4aeb-a5be-8391b9525339",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.7.\n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "F_x(t) = \\left\\{h(x) + t^{1/\\theta}\\right\\}^{\\theta}\n",
    "$$\n",
    "\n",
    "Prove that, for all $x\\in X$, the function $F_x$ is increasing,\n",
    "\n",
    "1.  convex whenever $\\theta\\in (0,1]$ and\n",
    "2.  concave otherwise for nonzero $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba5577-a943-4ce4-9560-2297c39d1bd1",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "This proof consists three parts. We first, prove $F_x$ is increasing with $t$.\n",
    "\n",
    "**Proof part 1**\n",
    "We first show that $F_x$ is increasing in $t$. Let $0<t_1\\le t_2$.\n",
    "\n",
    "For $\\theta>0$, we have, $t_1\\le t_2$ implies $t_1^{1/\\theta} \\le t_2^{1/\\theta}$, and $h(x)+t_1^{1/\\theta} \\le h(x)+t_2^{1/\\theta}$ for all $x\\in X$. Hence, \n",
    "\n",
    "$$\n",
    "F_x(t_1) = \\left\\{h(x) + t_1^{1/\\theta}\\right\\}^{\\theta}\\le \\left\\{h(x) + t_2^{1/\\theta}\\right\\}^{\\theta} =F_x(t_2)\n",
    "$$\n",
    "\n",
    "This shows that $F_x(t)$ is increasing with $t$ when $\\theta>0$.\n",
    "\n",
    "For $\\theta<0$, we have, $t_1\\le t_2$ implies $t_2^{1/\\theta} \\le t_1^{1/\\theta}$, and $h(x)+t_2^{1/\\theta} \\le h(x)+t_1^{1/\\theta}$ for all $x\\in X$. Hence, \n",
    "\n",
    "$$\n",
    "F_x(t_1) = \\left\\{h(x) + t_1^{1/\\theta}\\right\\}^{\\theta}\\le \\left\\{h(x) + t_2^{1/\\theta}\\right\\}^{\\theta} =F_x(t_2)\n",
    "$$\n",
    "\n",
    "This shows that $F_x(t)$ is increasing with $t$ for all $\\theta\\neq 0$.\n",
    "\n",
    "\n",
    "**Proof part 2**\n",
    "\n",
    "We now show that when $\\theta\\in (0,1]$, $F_x(t)$ is convex in $t$. \n",
    "\n",
    "To show convexity, we show the second order derivative of $F_x$ with respect to $t$ is always positive.\n",
    "\n",
    "First, we find the first order derivative,\n",
    "\n",
    "\\begin{align*}\n",
    "F_x'(t) &= \\theta \\{h(x)+t^{1/\\theta}\\}^{\\theta-1}\\frac{1}{\\theta}t^{1/\\theta-1}\\\\\n",
    "&= \\frac{t^{(1-\\theta)/\\theta}}{\\{h(x)+t^{1/\\theta}\\}^{1-\\theta}}\n",
    "\\end{align*}\n",
    "\n",
    "Then, we obtain the second order derivative,\n",
    "\n",
    "\\begin{align*}\n",
    "F_x''(t) &= \\frac{\\frac{1-\\theta}{\\theta}t^{(1-2\\theta)/\\theta}\\{h(x)+t^{1/\\theta}\\}^{-\\theta}h(x)}{\\{h(x)+t^{1/\\theta}\\}^{2-2\\theta}}\n",
    "\\end{align*}\n",
    "\n",
    "Since $h(x)\\gg 0$, and when $\\theta\\in(0,1]$, this implies $F_x''(t)\\gg 0$. Hence, $F_x(t)$ is convex.\n",
    "\n",
    "**Proof part 3**\n",
    "\n",
    "The third part follows immediately from the second order derivative is negative when $\\theta\\not\\in (0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff037b8f-ab61-42bf-897c-8fbf6b821b3a",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.8.\n",
    "\n",
    "Using EXERCISE 7.1.7., prove that $G$ is order-preserving on $V$, convex on $V$ whenever $\\theta\\in(0,1]$ and concave otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9190a4-0ff7-420e-8eb4-44457c9137a8",
   "metadata": {},
   "source": [
    "**Proof part 1**\n",
    "\n",
    "First, we prove that $G$ is order-preserving on $V$.\n",
    "\n",
    "Let $v,v'\\in V$ such that $v\\le v'$. Then, since $A$ is a positive linear operator, we have, \n",
    "\n",
    "$$\n",
    "(Av)(x)^{1/\\theta} \\le (Av')(x)^{1/\\theta}\n",
    "$$\n",
    "\n",
    "for all $x\\in X$.\n",
    "\n",
    "Then, we the result from EXERCISE 7.1.7. part 1, this gives the result that $G$ is order-preserving on $V$.\n",
    "\n",
    "**Proof part 2**\n",
    "\n",
    "Then, we show that $G$ is convex when $\\theta\\in(0,1]$. \n",
    "\n",
    "Using the result from EXERCISE 7.1.7 part 2, we know that for every $x\\in X$, we have, $G(\\lambda v + (1-\\lambda)v')(x)\\le \\lambda (Gv)(x)+(1-\\lambda) (Gv')(x)$. Hence, we have $G$ is convex when $\\theta\\in(0,1]$.\n",
    "\n",
    "**Proof part 3**\n",
    "\n",
    "Similar to part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b48cc-e604-41fb-917f-0dbe87b1756c",
   "metadata": {},
   "source": [
    "### EXERCISE 7.1.9.\n",
    "\n",
    "We study a dynamic discrete choice model of migration with savings and capital accumulation.\n",
    "\n",
    "The optimal consumption for landlords in their model is\n",
    "\n",
    "$$\n",
    "c_t = \\sigma_t R_t k_t\n",
    "$$\n",
    "\n",
    "where, $k_t$ is capital, $R_t$ is the gross rate of return on capital, and $\\sigma_t$ is a state-dependent process obeying\n",
    "\n",
    "$$\n",
    "\\sigma_t^{-1} = 1+\\beta^\\psi\\left[\\mathbb{E}_t R_{t+1}^{(\\psi-1)/\\psi}\\sigma_{t+1}^{-1/\\psi}\\right]^{\\psi}\n",
    "$$\n",
    "\n",
    "Here $\\beta$ is a discount factor and $\\psi$ is a utility parameter.\n",
    "\n",
    "Assume $R_t=f(X_t)$ where $X$ is finite, $f\\in\\mathbb{R}^X$, and $(X_t)$ is $P$-Markov for some $P\\in\\mathcal{M}(\\mathbb{R}^X)$.\n",
    "\n",
    "Let $A\\in\\mathcal{L}(\\mathbb{R}^X)$ be defined by\n",
    "\n",
    "$$\n",
    "(Av)(x) = \\beta\\sum_{x'} f(x')^{(\\psi-1)/\\psi} v(x') P(x,x')\n",
    "$$\n",
    "\n",
    "Prove that there exists a unique solution of the form $\\sigma_t =\\sigma(X_t)$ for some $\\sigma\\in\\mathbb{R}^X$ with $\\sigma \\gg 0$ if and only if $\\rho(A)^\\psi <1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf8751-e057-4d5d-bbbf-d4c41942fd28",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "$(\\implies)$\n",
    "\n",
    "Suppose there exists a unique solution of the form $\\sigma_t = \\sigma(X)$ for some $\\sigma\\in\\mathbb{R}^X$ with $\\sigma \\gg 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc5cf0-eaee-4d87-8a5f-49bf93db8d01",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.1\n",
    "\n",
    "Verify our guess: Show $(V_t^*)$ obeys (7.5) when $V_t^*=v^*(X_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbd919-3db4-42b7-9d87-1f3c8cfad0cd",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "Let $V^*_t = v^*(X_t)$ follows,\n",
    "\n",
    "$$\n",
    "v^*(x) = (I-\\beta P)^{-1} r(x)\n",
    "$$\n",
    "\n",
    "We want to show that $v^*(x) = (u\\circ c)(x) + \\beta \\mathbb{E}_t v^*(X_{t+1})$\n",
    "\n",
    "By Neumman series lemma, we have,\n",
    "\n",
    "$$\n",
    "v^*(x) = r(x) + \\beta (Pr)(x) + \\beta^2 (P^2 r)(x) +\\cdots\n",
    "$$\n",
    "\n",
    "By the Markov property, we have,\n",
    "\n",
    "$$\n",
    "\\beta (Pr)(x) + \\beta^2 (P^2 r)(x) +\\cdots = \\beta \\mathbb{E}_x v^*(X_{t+1}) = \\beta \\mathbb{E}_t v^*(X_{t+1})\n",
    "$$\n",
    "\n",
    "This gives the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1482e5-b37f-4584-8504-a3e921b5cf87",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.2\n",
    "\n",
    "Prove that for any random variable $\\xi$ any nonzero $\\theta$ and any constant $c$, we have,\n",
    "\n",
    "$$\n",
    "\\varepsilon_\\theta[\\xi +c] = \\varepsilon_\\theta[\\xi]+c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb71268-1488-4086-a8d2-6b01d56f0f28",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "\\begin{align*}\n",
    "\\varepsilon_\\theta[\\xi+c] &= \\frac{1}{\\theta}\\ln\\{\\mathbb{E}[\\exp(\\theta (\\xi+c))]\\}\\\\\n",
    "&= \\frac{1}{\\theta}\\ln\\{\\mathbb{E}[\\exp(\\theta \\xi+\\theta c)]\\}\\\\\n",
    "&= \\frac{1}{\\theta}\\ln\\{\\mathbb{E}[\\exp(\\theta \\xi)\\exp(\\theta c)]\\}\\\\\n",
    "&= \\frac{1}{\\theta}\\ln\\{\\mathbb{E}[\\exp(\\theta \\xi)]\\}+c\\\\\n",
    "&= \\varepsilon_\\theta[\\xi] +c\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5f6b8-61c3-4a58-979c-2e8bfdff18d5",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.3.\n",
    "\n",
    "Prove that if $\\xi$ is normally distributed, then\n",
    "\n",
    "$$\n",
    "\\varepsilon_\\theta [\\xi] = \\mathbb{E}[\\xi] + \\theta\\frac{Var[\\xi]}{2}\n",
    "$$\n",
    "\n",
    "Hint: Use the moment generating function of a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c43460-2a93-46b4-84c7-896f345b6938",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Suppose, $\\xi \\sim N(\\mathbb{E}[\\xi], Var[\\xi])$. Then, we know,\n",
    "\n",
    "$$\n",
    "\\exp(\\theta \\xi) \\sim lognormal(\\theta\\mathbb{E}[\\xi], \\theta^2Var[\\xi])\n",
    "$$\n",
    "\n",
    "This implies,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\exp(\\theta\\xi)] = \\exp\\left(\\theta\\mathbb{E}[\\xi]+\\theta^2\\frac{Var[\\xi]}{2}\\right)\n",
    "$$\n",
    "\n",
    "Hence, we have, \n",
    "\n",
    "$$\n",
    "\\varepsilon_\\theta[\\xi] = \\mathbb{E}[\\xi] + \\theta\\frac{Var[\\xi]}{2}\n",
    "$$\n",
    "\n",
    "This gives the proof. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9d491-76d5-49c7-9124-d539bca46861",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.4.\n",
    "\n",
    "Verify that $v(x)=ax+b$ solves \n",
    "\n",
    "$$\n",
    "v(x) = x + \\beta \\varepsilon_\\theta [v(\\rho x + \\sigma W)]\n",
    "$$\n",
    "\n",
    "when,\n",
    "\n",
    "$$\n",
    "a:=\\frac{1}{1-\\rho \\beta}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "b:= \\theta \\frac{\\beta}{1-\\beta} \\frac{(a\\sigma)^2}{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee01cbf-5448-4f7c-81dd-b5b41a1af104",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "\n",
    "We first assume $v(x) = ax+b$ and substitute in the first equation. We get,\n",
    "\n",
    "$$\n",
    "ax+b = x + \\beta \\varepsilon_\\theta[a\\rho x + a\\sigma W + b]\n",
    "$$\n",
    "\n",
    "Using the functional form of $\\varepsilon_\\theta$, we have,\n",
    "\n",
    "\\begin{align*}\n",
    "\\varepsilon_\\theta[a\\rho x + a\\sigma W +b] &= \\frac{1}{\\theta}\\ln\\left\\{\\mathbb{E}[\\exp(a\\theta \\rho x + a\\theta\\sigma W + \\theta b)]\\right\\}\\\\\n",
    "&= \\frac{1}{\\theta}\\ln\\left\\{\\int_{w}\\exp(a\\theta \\rho x + a\\theta\\sigma w + \\theta b)\\,\\,d\\phi(w)\\right\\}\\\\\n",
    "&= \\frac{1}{\\theta}\\ln\\left\\{\\int_{w}\\exp(a\\theta \\rho x)\\exp(\\theta b) \\exp(a\\theta\\sigma w)\\,\\,d\\phi(w)\\right\\}\\\\\n",
    "&= \\frac{1}{\\theta}\\ln\\left\\{\\exp(a\\theta \\rho x)\\exp(\\theta b) \\int_{w}\\exp(a\\theta\\sigma w)\\,\\,d\\phi(w)\\right\\}\\\\\n",
    "&= a\\rho x + b + \\frac{1}{\\theta}\\ln \\int_w \\exp(a\\theta \\sigma w) \\,\\,d\\phi(w)\n",
    "\\end{align*}\n",
    "\n",
    "Since, $W\\sim N(0,1)$, this implies $\\exp(a\\theta W)\\sim log N(0, a^2 \\theta^2\\sigma^2)$ and we have,\n",
    "\n",
    "\\begin{align*}\n",
    "\\varepsilon_\\theta[a\\rho x + a\\sigma W +b] &= a\\rho x + b + \\frac{1}{\\theta} \\ln(\\exp(0+\\frac{(a\\sigma)^2 \\theta^2}{2}))\\\\\n",
    "&= a\\rho x + b + \\frac{(a\\sigma)^2 \\theta}{2}\n",
    "\\end{align*}\n",
    "\n",
    "Substituting this back to the first equation, we can verify the claim.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c857d-cc42-49a4-96c2-c8eb7353fc5e",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.6.\n",
    "\n",
    "Dropping the Gaussian assumption, suppose now that consumption is IID with $C_t = c(X_t)$ where $(X_t)_{t\\ge 0}$ is IID with distribution $\\varphi$ on finite set $X$. Now the operator $K_\\theta$ becomes\n",
    "\n",
    "$$\n",
    "(K_\\theta v)(x) r(x)+\\beta\\frac{1}{\\theta}\\ln\\left\\{\\sum_{x'} \\exp(\\theta v(x'))\\varphi(x')\\right\\}\n",
    "$$\n",
    "\n",
    "Although iterating on $K_\\theta$ is convergent, there is a more efficient method that reduces to solving a one-dimensional equation. Propose such a method and confirm that it is convergent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7263515-a2cd-4192-8b07-906b25fb847b",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Let $g = \\sum_{x'}\\exp(\\theta v(x'))\\varphi(x')$. Then we have,\n",
    "\n",
    "$$\n",
    "v(x) = r(x) + \\beta \\frac{1}{\\theta \\ln g}\n",
    "$$\n",
    "\n",
    "Then, we can obtain the one-dimensional problem:\n",
    "\n",
    "\\begin{align*}\n",
    "g &= \\sum_{x'} \\exp(\\theta (r(x')+\\beta\\frac{1}{\\theta}\\ln g))\\varphi(x')\\\\\n",
    "&= \\sum_{x'} \\exp(\\theta (r(x'))\\exp(\\beta\\ln g))\\varphi(x')\\\\\n",
    "&=\\exp(\\beta)g\\sum_{x'} \\exp(\\theta (r(x'))\\varphi(x')\\\\\n",
    "&= \\frac{\\sum_{x'} \\exp(\\theta (r(x'))\\varphi(x')\\\\}{1-\\exp \\beta}\n",
    "\\end{align*}\n",
    "\n",
    "Hence, we can obtain the unique solution when $\\beta\\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6b09f-a72f-4cd4-b2c8-c1b57b8615de",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.7. \n",
    "\n",
    "Prove that under this assumption ($h\\ge 0$), $K$ is a self-map on $V=(0,\\infty)^X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e164dab-5bf4-4af6-b11a-fa6618c81fa1",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "Kv = \\left\\{h + \\beta (Pv^\\gamma)^{\\alpha/\\gamma}\\right\\}^{1/\\alpha}\n",
    "$$\n",
    "\n",
    "and we want to show that,\n",
    "\n",
    "$$\n",
    "v\\in (0,\\infty)^X \\implies Kv \\in (0,\\infty)^X\n",
    "$$\n",
    "\n",
    "Let $v\\in (0,\\infty)^X$, since $P$ is a Markov matrix, we have,\n",
    "\n",
    "$$\n",
    "\\beta(Pv^\\gamma)^{\\alpha/\\gamma}\\in (0,\\infty)^X\n",
    "$$\n",
    "\n",
    "moreover, since we assume, $h\\in (0,\\infty)^X$.\n",
    "\n",
    "Hence, we have $Kv\\in(0,\\infty)^X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28f59b-0fba-4e40-9ef5-d6b29cb0f744",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.8.\n",
    "\n",
    "Prove that\n",
    "\n",
    "1. $\\hat K$ is a self-map on $V$\n",
    "2. $v\\in V$ is a fixed point of $K$ if and only if $v^\\gamma$ is a fixed point of $\\hat K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ad404-e084-4bf2-986e-fa7131406eb8",
   "metadata": {},
   "source": [
    "**Proof part 1**\n",
    "\n",
    "The proof will very similar to EXERCISE 7.2.7. We have,\n",
    "\n",
    "$$\n",
    "\\hat{K}v = \\left\\{h + \\beta (Pv)^{1/\\theta}\\right\\}^{\\theta}\n",
    "$$\n",
    "\n",
    "Then if $v\\in V$, this implies $Pv\\in v$, and hence $\\hat{K}v\\in V$.\n",
    "\n",
    "**Proof part 2**\n",
    "\n",
    "$(\\implies)$\n",
    "\n",
    "Suppose $v\\in V$ is a fixed point of $K$, we have $Kv =v$.\n",
    "\n",
    "Then we have,\n",
    "\n",
    "$$\n",
    "\\hat{K}v^\\gamma = \\left\\{h + \\beta (Pv^\\gamma)^{1/\\theta}\\right\\}^{\\theta} = (Kv)^\\gamma = v^\\gamma\n",
    "$$\n",
    "\n",
    "$(\\impliedby)$\n",
    "\n",
    "Suppose $v^\\gamma \\in V$ is a fixed point of $\\hat K$, we have,\n",
    "\n",
    "$$\n",
    "\\hat{K}v^\\gamma = \\left\\{h + \\beta (Pv^\\gamma)^{1/\\theta}\\right\\}^{\\theta} = (Kv)^\\gamma = v^\\gamma\n",
    "$$\n",
    "\n",
    "Hence, this implies $Kv = v$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b885d1f-d677-4b17-9697-e1a3337de314",
   "metadata": {},
   "source": [
    "### EXERCISE 7.2.9.\n",
    "\n",
    "Prove that, given the parameter values used for Figure 7.5, the function $F$ satisfies $F'(t)\\to\\infty$ as $t\\to 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2288ab4b-9f60-46c8-b113-671be482ace3",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have \n",
    "\n",
    "$$\n",
    "F(t) = \\{0.5+0.5 t^{1/5}\\}^5\n",
    "$$\n",
    "\n",
    "This implies, we have,\n",
    "\n",
    "$$\n",
    "F'(t) = 0.5\\{0.5+0.5 t^{1/5}\\}^{4}t^{-4/5}\n",
    "$$\n",
    "\n",
    "Hence, we have as $t\\to 0_+$, $F'(t)\\to \\infty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9da9c9-ee9b-46cf-ac56-fd693e2c27fd",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.1.\n",
    "\n",
    "In Example 7.3.1., the certainty equivalent operator $R=P$ is linear. \n",
    "\n",
    "Prove that this is the only linear case.\n",
    "\n",
    "In particular, prove \n",
    "\n",
    "if $R(X)$ is the set of all certainty equivalent operators on $\\mathbb{R}^X$, then $R(X) \\cap \\mathcal{L}(\\mathbb{R}^X) = \\mathcal{M}(\\mathbb{R}^X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88c38e-ac18-47fb-8811-c5cc76b71e82",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Since we have already proved that for any $P\\in \\mathcal{M}(\\mathbb{R}^X)$, we have, $P\\in R(X)$ and $P\\in \\mathcal{L}(\\mathbb{R}^X)$. Hence, we have,\n",
    "\n",
    "$$\n",
    "\\mathcal{M}(\\mathbb{R}^X)\\subset R(X) \\cap \\mathcal{L}(\\mathbb{R}^X) \n",
    "$$\n",
    "\n",
    "Now, we wish to \n",
    "\n",
    "$$\n",
    "R(X) \\cap \\mathcal{L}(\\mathbb{R}^X)\\subset \\mathcal{M}(\\mathbb{R}^X)\n",
    "$$\n",
    "\n",
    "Let $Q\\in R(X) \\cap \\mathcal{L}(\\mathbb{R}^X)$. We want to check that $Q$ is increasing and has row sum 1. \n",
    "\n",
    "Since $Q\\in R(X)$, then, $Q$ is order-preserving, hence $Q$ is increasing.\n",
    "\n",
    "Moreover, since $Q\\in R(X)$, we have $Q\\mathbb{1}=\\mathbb{1}$. This implies $Q$ has row sum 1. \n",
    "\n",
    "This completes the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94ede8-7f91-4977-9db5-fd3b64a6f30a",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.2.\n",
    "\n",
    "Show that $R_\\theta$ is in fact a certainty equivalent operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287d55cf-d402-4ef9-89b9-d078d49cabe6",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have\n",
    "\n",
    "$$\n",
    "R_\\theta v = \\frac{1}{\\theta} \\ln\\left\\{(P\\exp(\\theta v))\\right\\}\n",
    "$$\n",
    "\n",
    "We want to show three things:\n",
    "\n",
    "1. $R_\\theta$ is a self-map on $\\mathbb{R}^X$\n",
    "2. $R_\\theta$ is order-preserving\n",
    "3. $R_\\theta(\\lambda\\mathbb{1})=\\lambda\\mathbb{1}$\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Let $v\\in \\mathbb{R}^X$, we have $P\\exp(\\theta v)\\ge \\mathbb{0}$, hence $R_\\theta v\\in \\mathbb{R}^X$.\n",
    "\n",
    "This proves part 1.\n",
    "**Part 2**\n",
    "Let $v,v'\\in V$ and $v\\le v'$, then we have,\n",
    "\n",
    "$$\n",
    "R_\\theta v = \\frac{1}{\\theta} \\ln\\left\\{(P\\exp(\\theta v))\\right\\}\\le \\frac{1}{\\theta} \\ln\\left\\{(P\\exp(\\theta v'))\\right\\} = R_\\theta v'\n",
    "$$\n",
    "\n",
    "This is because $\\exp, \\theta, \\ln, P$ are all order-preserving.\n",
    "\n",
    "This proves part 2.\n",
    "\n",
    "**Part 3**\n",
    "\n",
    "Let $\\lambda\\in \\mathbb{R}$, then we have,\n",
    "\n",
    "\\begin{align*}\n",
    "R_\\theta(\\lambda \\mathbb{1}) &= \\frac{1}{\\theta} \\ln\\left\\{(P\\exp(\\theta\\lambda \\mathbb{1}))\\right\\}\\\\\n",
    "&= \\frac{1}{\\theta} \\ln\\left\\{(\\exp(\\theta\\lambda \\mathbb{1}))\\right\\}\\\\\n",
    "&= \\lambda \\mathbb{1}\n",
    "\\end{align*}\n",
    "\n",
    "This proves part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d0b8c-cd33-47f6-aaa5-228f4d9295d9",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.3. \n",
    "\n",
    "Confirm that $R_\\gamma$ is a certainty equivalent operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672715b-5166-4241-8672-e1cdc66f1532",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We check three conditions:\n",
    "\n",
    "1. $R_\\gamma$ is a self-map on the interior of the positive cone.\n",
    "2. $R_\\gamma$ is order-preserving\n",
    "3. $R_\\gamma(\\lambda \\mathbb{1})=\\lambda\\mathbb{1}$\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Let $v\\in V$, since all the transformations are invariant in the interior of the positive cone, we have $R_\\gamma v\\in V$.\n",
    "\n",
    "This gives the first part.\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "Let $v,v'\\in V$ and $v\\le v'$. Then we have,\n",
    "\n",
    "$$\n",
    "R_\\gamma v = \\left\\{Pv^\\gamma\\right\\}^{1/\\gamma}\\le\\left\\{Pv'^\\gamma\\right\\}^{1/\\gamma} = R_\\gamma v'\n",
    "$$\n",
    "\n",
    "as all transformations are order-preserving.\n",
    "\n",
    "This proves part 2.\n",
    "\n",
    "**Part 3**\n",
    "\n",
    "Let $\\lambda\\in\\mathbb{R}$, we have,\n",
    "\n",
    "$$\n",
    "R_\\gamma \\lambda\\mathbb{1} = \\left\\{P(\\lambda\\mathbb{1}^\\gamma)\\right\\}^{1/\\gamma} = \\left\\{\\lambda^\\gamma\\mathbb{1}\\right\\}^{1/\\gamma}=\\lambda\\mathbb{1}\n",
    "$$\n",
    "\n",
    "This proves part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93916639-8c47-4005-8c7c-145a5c2c0bd9",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.4.\n",
    "\n",
    "Let $V=\\mathbb{R}^X$ and fix $P\\in\\mathcal{M}(\\mathbb{R}^X)$ and $\\tau\\in[0,1]$. Let $R_\\tau$ be the **quantile certainty equivalent**.\n",
    "\n",
    "That is $(R_\\tau v)(x) = Q_\\tau v(X)$ where $X\\sim P(x,\\cdot)$ and $Q_\\tau$ is the quantile functional.\n",
    "\n",
    "More specifically,\n",
    "\n",
    "$$\n",
    "(R_\\tau v)(x) =\\min\\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v(x')\\le y\\} P(x,x')\\ge \\tau\\right\\}\n",
    "$$\n",
    "\n",
    "Confirm that $R_\\tau$ defines a certainty equivalent operator on $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea5ea7-d5f7-4065-9d28-67985880727d",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We need to check three parts:\n",
    "\n",
    "1. $R_\\tau$ is a self-map on $V$\n",
    "2. $R_\\tau$ is order-preserving\n",
    "3. $R_\\tau \\lambda\\mathbb{1} = \\lambda\\mathbb{1}$\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Let $v\\in V$. Since $X$ is finite, there exists $M<\\infty$ such that $M\\ge v(x)$ for all $x\\in X$. Hence, $R_\\tau v \\in V$.\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "Let $v,v'\\in V$ and $v\\le v'$. We have,\n",
    "\n",
    "$$\n",
    "\\mathbb{1}\\{v'(x')\\le y\\} \\le \\mathbb{1}\\{v(x')\\le y\\}\n",
    "$$\n",
    "\n",
    "Hence, since conditional expectation is order-preserving, we have,\n",
    "\n",
    "$$\n",
    "\\sum_{x'}\\mathbb{1}\\{v'(x')\\le y\\} P(x,x')\\le\\sum_{x'}\\mathbb{1}\\{v(x')\\le y\\} P(x,x')\n",
    "$$\n",
    "\n",
    "Thus, we have\n",
    "\n",
    "$$\n",
    "\\tau\\le \\sum_{x'}\\mathbb{1}\\{v'(x')\\le y\\} P(x,x')\\le\\sum_{x'}\\mathbb{1}\\{v(x')\\le y\\} P(x,x')\n",
    "$$\n",
    "\n",
    "Hence, we have,\n",
    "\n",
    "$$\n",
    "\\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v'(x')\\le y\\} P(x,x')\\ge \\tau\\right\\}\\subset \\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v(x')\\le y\\} P(x,x')\\ge \\tau\\right\\}\n",
    "$$\n",
    "\n",
    "Hence, we have,\n",
    "\n",
    "$$\n",
    "R_\\tau v\\le R_\\tau v'\n",
    "$$\n",
    "\n",
    "**Part 3**\n",
    "\n",
    "Let $\\lambda\\in \\mathbb{R}$. We have,\n",
    "\n",
    "$$\n",
    "R_\\tau \\lambda\\mathbb{1} (x) = \\min\\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{\\lambda\\le y\\} P(x,x')\\ge \\tau\\right\\}\n",
    "$$\n",
    "\n",
    "We have $y<\\lambda$ \\implies $\\sum_{x'} \\mathbb{1}\\{\\lambda\\le y\\} P(x,x') =0$, and $y\\ge \\lambda$ implies $\\sum_{x'} \\mathbb{1}\\{\\lambda\\le y\\} P(x,x') =1 \\ge \\tau$ hence,\n",
    "\n",
    "$$\n",
    "\\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{\\lambda\\le y\\} P(x,x')\\ge \\tau\\right\\} = \\{y\\in\\mathbb{R}: y\\ge \\lambda\\}\n",
    "$$\n",
    "\n",
    "Therefore, we have $R_\\tau\\lambda \\mathbb{1} = \\lambda \\mathbb{1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5308ddc-7abd-4330-a50a-c7a45c64e2df",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.5.\n",
    "\n",
    "Let $R$ be a certainty equivalent operator on $V\\subset\\mathbb{R}_+^X$, where $\\lambda\\mathbb{1}\\in V$ for all $\\lambda \\ge 0$.\n",
    "\n",
    "Prove that $R0=0$ and $Rv\\ge 0$ whenever $v\\ge 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f334b1a9-89d6-49bc-950b-11f2d3a65e6e",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Since $R$ is a certainty equivalent operator, we have when $\\lambda=0$, \n",
    "\n",
    "$$\n",
    "R0\\mathbb{1} = 0\\mathbb{1}=0\n",
    "$$\n",
    "\n",
    "Moreover, we have $R$ is order-preserving, this implies\n",
    "\n",
    "$$\n",
    "v\\ge 0 \\implies Rv\\ge R0=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac427975-0417-4fd8-9ad5-75a2127139f9",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.6. \n",
    "\n",
    "Let $R(x)$ be the set of certainty equivalent operators on $\\mathbb{R}^X$ and prove that\n",
    "\n",
    "$$\n",
    "R_a, R_b \\in R(x), \\lambda\\in [0,1] \\implies \\lambda R_a + (1-\\lambda)R_b\\in R(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31faeaa0-47da-4be6-8173-65b920d45181",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We need to prove three parts\n",
    "\n",
    "1. $\\lambda R_a + (1-\\lambda)R_b$ is a self-map on $\\mathbb{R}^X$\n",
    "2. $\\lambda R_a + (1-\\lambda)R_b$ is order-preserving\n",
    "3. $[\\lambda R_a + (1-\\lambda)R_b]\\mu\\mathbb{1} =\\mu\\mathbb{1}$\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Since $R_a, R_b$ are self-maps, hence $\\lambda R_a + (1-\\lambda)R_b$ is also self-maps.\n",
    "\n",
    "This proves part 1.\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "Since $R_a, R_b$ are order-preserving and convex combination is also order-preserving, hence $\\lambda R_a + (1-\\lambda)R_b$ is also order-preserving.\n",
    "\n",
    "This proves part 2.\n",
    "\n",
    "**Part 3**\n",
    "\n",
    "Let $\\mu\\in\\mathbb{R}$, we have,\n",
    "\n",
    "\\begin{align*}\n",
    "[\\lambda R_a + (1-\\lambda)R_b]\\mu\\mathbb{1} &= \\lambda R_a \\mu\\mathbb{1} + (1-\\lambda)R_b \\mu\\mathbb{1} \\\\\n",
    "&= \\lambda \\mu \\mathbb{1}+ (1-\\lambda)\\mu\\mathbb{1}\\\\\n",
    "&= \\mu\\mathbb{1}\n",
    "\\end{align*}\n",
    "\n",
    "This proves part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6a4e5f-d3ff-4de9-986e-af422ad9d920",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.7. \n",
    "\n",
    "Prove that the quantile certainty equivalent operator $R_\\tau$ from EXERCISE 7.3.4. is constant-subadditive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641551f9-60d5-47f6-9a98-ddf2cc3da9d8",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "(R_\\tau v)(x) =\\min\\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v(x')\\le y\\} P(x,x')\\ge \\tau\\right\\}\n",
    "$$\n",
    "\n",
    "Let $\\lambda\\ge 0$ with $v+\\lambda \\mathbb{1}\\in V$. We have,\n",
    "\n",
    "\\begin{align*}\n",
    "R_\\tau (v+\\lambda \\mathbb{1})(x)&=  \\min\\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v(x')+\\lambda\\le y\\} P(x,x')\\ge \\tau\\right\\}\\\\\n",
    "&=  \\min\\left\\{y\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v(x')\\le y-\\lambda\\} P(x,x')\\ge \\tau\\right\\}\\\\\n",
    "&=  \\min\\left\\{y-\\lambda+\\lambda\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v(x')\\le y-\\lambda\\} P(x,x')\\ge \\tau\\right\\}\\\\\n",
    "&= \\min\\left\\{y-\\lambda\\in \\mathbb{R}\\bigg| \\sum_{x'} \\mathbb{1}\\{v(x')\\le y-\\lambda\\} P(x,x')\\ge \\tau\\right\\} + \\lambda\\\\\n",
    "&= R_\\tau v (x) + \\lambda\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa29766-7143-487e-8089-b34c6dc76290",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.8.\n",
    "\n",
    "Show that the entropic certainty equivalent operator $R_\\theta$ from example 7.3.2. is constant-subadditive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b42b43-b552-463f-8e36-b7e8525fc48b",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "(R_\\theta v)(x) =\\frac{1}{\\theta}\\ln\\left\\{\\sum_{x'} \\exp(\\theta v(x'))P(x,x')\\right\\}\n",
    "$$\n",
    "\n",
    "Let $\\lambda \\ge 0$, we have,\n",
    "\n",
    "\\begin{align*}\n",
    "R_\\theta (v+\\lambda \\mathbb{1})(x) &=\\frac{1}{\\theta}\\ln\\left\\{\\sum_{x'} \\exp(\\theta (v(x')+\\lambda))P(x,x')\\right\\} = R_\\theta v(x)+\\lambda\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895b12a-35b1-48e6-925d-f883f7dbb619",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.9.\n",
    "\n",
    "Prove if $R$ is constant-subadditive on $V$, then $R$ is nonexpansive with respect to the supremum norm. \n",
    "\n",
    "That is\n",
    "\n",
    "$$\n",
    "\\|Rv-Rw\\|_\\infty \\le \\|v-w\\|_\\infty\n",
    "$$\n",
    "\n",
    "for all $v,w\\in \\mathbb{R}^X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0240a72-d98d-4eb6-b089-5d123c8e3ec4",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "$R$ is constant-subadditive on $V$ implies,\n",
    "\n",
    "$$\n",
    "R(v+\\lambda\\mathbb{1})\\le R(v)+\\lambda\\mathbb{1}\n",
    "$$\n",
    "\n",
    "Hence, by order-preserving, we have,\n",
    "\n",
    "$$\n",
    "(Rv)(x) = R(v-w+w)(x)\\le R(\\|v-w\\|_\\infty + w)(x)\\le (Rw)(x)+\\|v-w\\|_\\infty\n",
    "$$\n",
    "\n",
    "for all $x\\in X$.\n",
    "\n",
    "Hence, applying the same argument, we prove this claim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826229d-3e70-434a-a2e1-a8f5972867c1",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.10 \n",
    "\n",
    "Use \n",
    "\n",
    "$$\n",
    "\\varepsilon_\\theta(\\alpha Z+(1-\\alpha)Z') \\ge \\alpha \\varepsilon_\\theta (Z)+ (1-\\alpha)\\varepsilon_\\theta(Z')\n",
    "$$\n",
    "\n",
    "to show that $R_\\theta$ is concave on $V=\\mathbb{R}^X$ when $\\theta<0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc6c621-41db-4bd8-83f2-33284ce99bc3",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Let $v,v'\\in V$.  We have,\n",
    "\n",
    "$$\n",
    "R_\\theta(\\alpha v+(1-\\alpha)v') = \\varepsilon_\\theta(\\alpha v+(1-\\alpha)v')\\ge \\alpha\\varepsilon_\\theta(v)+(1-\\alpha)\\varepsilon_\\theta(v') = \\alpha R_\\theta v + (1-\\alpha) R_\\theta v'\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36109757-38c5-4d2c-bdee-4fa6398f0c52",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.11\n",
    "\n",
    "Let $V$ be convex and let $R$ be a certainty equivalent operator on $V$.\n",
    "\n",
    "Prove\n",
    "\n",
    "1. $R$ is convex on $V$ whenever $R$ is subadditive and positive homogeneous on $V$.\n",
    "2. $R$ is concave on $V$ whenever $R$ is superadditive and positive homogeneous on $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a46aede-6c2a-4bc0-ae83-390c12874662",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Let $R$ be subadditive and positive homogenous.\n",
    "\n",
    "We have, for any $\\alpha \\in (0,1)$\n",
    "\n",
    "$$\n",
    "R(\\alpha v + (1-\\alpha) v') \\le R(\\alpha v) + R((1-\\alpha)v')=\\alpha Rv+(1-\\alpha) Rv'\n",
    "$$\n",
    "\n",
    "**Part 2**\n",
    "\n",
    "Let $R$ be superadditive and positive homogenous.\n",
    "\n",
    "We have, for any $\\alpha \\in (0,1)$\n",
    "\n",
    "$$\n",
    "R(\\alpha v + (1-\\alpha) v') \\ge R(\\alpha v) + R((1-\\alpha)v')=\\alpha Rv+(1-\\alpha) Rv'\n",
    "$$\n",
    "\n",
    "These two parts give the full proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723d9fb9-8875-4754-bc38-51d45e4cd256",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.12.\n",
    "\n",
    "Show that the entropic certainty equivalent operator in Example 7.3.2. is monotone increasing on $V=\\mathbb{R}^X$ whenever $P$ is monotone increasing, for all nonzero values of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9595cd-ef83-46cb-a6c0-9ad342cdac33",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "(R_\\theta v)(x) =\\frac{1}{\\theta}\\ln\\left\\{\\sum_{x'} \\exp(\\theta v(x'))P(x,x')\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e24f8-d4bc-4639-8c8f-4758e6126f92",
   "metadata": {},
   "source": [
    "Let $v\\in i\\mathbb{R}^X$, we want show that $R_\\theta v\\in i\\mathbb{R}^X$.\n",
    "\n",
    "For $\\theta >0$, since $\\exp,\\ln$ are order-preserving, and $P$ is invariant on $i\\mathbb{R}^X$, hence, we have, $R_\\theta v\\in i\\mathbb{R}^X$.\n",
    "\n",
    "For $\\theta<0$, since $\\theta, 1/\\theta$ will cancel out on the ordering, we still have $R_\\theta v\\in i\\mathbb{R}^X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe5c6aa-7598-4879-8562-ac681b00c889",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.13.\n",
    "\n",
    "Show that the Kreps-Porteus certainty equivalent operator in Example 7.3.3. is monotone increasing on $V=(0,\\infty)^X$ whenever $P$ is monotone increasing, for all nonzero values of $\\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f3d75-d1db-4d6c-af56-fa1ba5f7fa00",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "(R_\\gamma v)(x) = \\left\\{\\sum_{x'}v(x')^\\gamma P(x,x')\\right\\}^{1/\\gamma}\n",
    "$$\n",
    "\n",
    "Let $v\\in i\\mathbb{R}^X$.\n",
    "\n",
    "When $\\gamma>0$, we have $v^\\gamma \\in i\\mathbb{R}^X$, hence, by $P$ is monotone increasing, $R_\\gamma v\\in i\\mathbb{R}^X$.\n",
    "\n",
    "When $\\gamma<0$, we have $\\left\\{\\sum_{x'}v(x')^\\gamma P(x,x')\\right\\} \\in d\\mathbb{R}^X$, and by $1/\\gamma<0$ $R_\\gamma v\\in i\\mathbb{R}^X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965479c9-1a84-41f1-aec1-31fbd3499994",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.14.\n",
    "\n",
    "Consider $U(c,y)=((1-\\beta)c^\\alpha + \\beta y^\\alpha)^{1/\\alpha}$ as a utility function over current and future goods $c$ and $y$.\n",
    "\n",
    "Then, $EIS = \\frac{d\\ln (y/c)}{d\\ln (U_c/U_y)}$ where $U_c = \\frac{\\partial U(c,y)}{\\partial c}, U_y = \\frac{\\partial U(c,y)}{\\partial y} $\n",
    "\n",
    "Confirm that $EIS =1/(1-\\alpha)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284219f-7a28-463a-82b0-d5d20d0f14bd",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "U_c = (1/\\alpha) ((1-\\beta)c^\\alpha + \\beta y^\\alpha)^{(1/\\alpha)-1}(1-\\beta)\\alpha c^{\\alpha-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "U_y = (1/\\alpha) ((1-\\beta)c^\\alpha + \\beta y^\\alpha)^{(1/\\alpha)-1}\\beta\\alpha y^{\\alpha-1}\n",
    "$$\n",
    "\n",
    "Hence,\n",
    "\n",
    "$$\n",
    "\\frac{U_c}{U_y} = \\frac{1-\\beta}{\\beta} \\left(\\frac{y}{c}\\right)^{1-\\alpha}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ln\\left(\\frac{U_c}{U_y}\\right) = \\ln\\left(\\frac{1-\\beta}{\\beta}\\right) + (1-\\alpha)\\ln\\left(\\frac{y}{c}\\right)\n",
    "$$\n",
    "\n",
    "Hence, this gives\n",
    "\n",
    "$$\n",
    "EIS = \\frac{d\\ln (y/c)}{d\\ln (U_c/U_y)} = \\frac{1}{1-\\alpha}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a347a-c2fd-479b-bbf3-732c4ddc0980",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.15.\n",
    "\n",
    "Consider again the time addtive preferences $V_t = u(C_t)+\\beta\\mathbb{E}_t V_{t+1}$.\n",
    "\n",
    "Suppose that the time horizon is finite, with some exogenous terminal value $V_m= w(X_m)$ at time $m$.\n",
    "\n",
    "Letting $v_m(x)$ represent lifetime value up until time $m$, conditional on initial state $x$, show that,\n",
    "\n",
    "1. $v_m = \\sum_{t=0}^{m-1} (\\beta P)^t r + (\\beta P)^m w$\n",
    "2. $v_m = K^m w $ where $K$ is the associated Koopmans operator $Kv=r+\\beta Pv$ and\n",
    "3. $K^mw\\to v^* = (I-\\beta P)^{-1}$ as $m\\to\\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aafeee7-0798-4e74-83be-c90bd71d9c92",
   "metadata": {},
   "source": [
    "**Proof part 1**\n",
    "\n",
    "By definition, we have,\n",
    "\n",
    "$$\n",
    "v_m = r + \\beta Pr + \\cdots + (\\beta P)^m w = \\sum_{t=0}^{m-1}(\\beta P)^t r+ (\\beta P)^m w\n",
    "$$\n",
    "\n",
    "**Proof part 2**\n",
    "\n",
    "\\begin{align*}\n",
    "K^m w &= K^{m-1} Kw \\\\\n",
    "&= K^{m-1} (r+\\beta P w)\\\\\n",
    "&= K^{m-2} K(r+\\beta P w)\\\\\n",
    "&= K^{m-2} (r+ \\beta P r + (\\beta P)^2 w)\\\\\n",
    "&\\vdots\\\\\n",
    "&= \\sum_{t=0}^{m-1}(\\beta P)^t r+ (\\beta P)^m w\\\\\n",
    "&=v_m\n",
    "\\end{align*}\n",
    "\n",
    "**Proof part 3**\n",
    "\n",
    "As $m\\to\\infty$, we have,\n",
    "\n",
    "$$\n",
    "K^m w = \\sum_{t=0}^{m-1}(\\beta P)^t r+ (\\beta P)^m w\\to \\sum_{t=0}^\\infty (\\beta P)^t r = v^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7d68c-6eeb-44e1-867c-6fcbbcf10293",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.16.\n",
    "\n",
    "Consider the Epstein-Zin Koopmans operator $K=A_{CES} \\circ R_\\gamma$ on $V$, where $V=(0,\\infty)^X$ and the preimitives is \n",
    "\n",
    "$$\n",
    "(Kv)(x)=\\left\\{h +\\beta \\left[\\sum_{x'} v(x')^\\gamma P(x,x')\\right]^{\\alpha/\\gamma}\\right\\}^{1/\\alpha}\n",
    "$$\n",
    "\n",
    "Assume the conditions of $P$ is irreducible, and $h\\gg 0$, so that $K$ has a unique fixed point $v^*\\in V$.\n",
    "\n",
    "Given $P\\in\\mathcal{M}(\\mathbb{R}^X)$, we can write $R_\\gamma$ as $R_\\gamma v = (Pv^\\gamma)^{1/\\gamma}$ at each $v\\in V$.\n",
    "\n",
    "Prove that $v^*$ is increasing in $X$ whenever $P$ is monotone increasing and $c\\in i\\mathbb{R}^X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194cb836-51ce-4e54-871f-00b63b419923",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Since we have globally stability, we need to show that\n",
    "\n",
    "1. $A(x,v)\\le A(x',v)$ whenever $v\\in V$ and $x\\precsim x'$\n",
    "2. $R$ is monotone increasing on $V$.\n",
    "\n",
    "We have proved part 2 before.\n",
    "\n",
    "Hence, we need to show that $A_{CES}$ satisfies part 1.\n",
    "\n",
    "We have, let $x,x'\\in X$ and $x\\precsim x'$, \n",
    "\n",
    "$$\n",
    "A_{CES}(x,v) = \\{c(x)^\\alpha +\\beta v^\\alpha\\}^{1/\\alpha}\\le \\{c(x')^\\alpha +\\beta v^\\alpha\\}^{1/\\alpha} = A_{CES}(x',v)\n",
    "$$\n",
    "\n",
    "as $c\\in i\\mathbb{R}^X$.\n",
    "\n",
    "Hence, using lemma 7.3.2, we get the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c213b8e0-fd0c-4050-acc2-32cce75e5a5f",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.17. \n",
    "\n",
    "Fix $\\beta\\in\\mathbb{R}_+$ and $r\\in\\mathbb{R}^X$. \n",
    "\n",
    "Show that the additive aggregator $A(x,y)= r(x)+\\beta y$ and the Leontief aggregator $A(x,y) = \\min\\{r(x), \\beta y\\}$ are Blackwell aggregators when $\\beta<1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd2a1b-dd40-4ff9-b120-e5922a8d28e3",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "For the additive aggregator, we have,\n",
    "\n",
    "$$\n",
    "A(x,y+\\lambda) = r(x)+\\beta(y+\\lambda) = r(x)+\\beta y + \\beta\\lambda = A(x,y) +\\beta \\lambda\n",
    "$$\n",
    "\n",
    "For the Leontief aggregator, we have,\n",
    "\n",
    "$$\n",
    "A(x,y+\\lambda) = \\min\\{r(x), \\beta (y+\\lambda)\\} \\le \\min\\{r(x)+\\beta\\lambda, \\beta y +\\beta\\lambda\\} = \\min\\{r(x), \\beta y\\}+\\beta\\lambda = A(x,y)+\\beta\\lambda\n",
    "$$\n",
    "\n",
    "Hence, when $\\beta<1$, they are Blackwell aggregators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91acbe7-dad0-4b20-b3dc-3aba1cb3db8d",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.18.\n",
    "\n",
    "Let $K=A_{MIN}\\circ R$ on $V=\\mathbb{R}^X$.\n",
    "\n",
    "Prove that $K$ is globally stable on $V$ whenever $R$ is constant-subadditive and $A_{MIN}(x,y) = \\min\\{r(x), \\beta y\\}$ with $\\beta\\in (0,1)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770d985-0add-406b-8cc6-802bfb4e8256",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have shown in EXERCISE 7.3.17. that $A_{MIN}$ is a Blackwell aggregator. Hence, Using Propositionn 7.3.3., we get $K$ is a contraction on $V$, hence we have global stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c370d-b2cc-4dda-a95c-051fe8a27b22",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.19.\n",
    "\n",
    "Consider replacing the operator $K_\\tau = A_{ADD}\\circ R_\\tau$ in\n",
    "\n",
    "$$\n",
    "(K_\\tau v) (x) = r(x)+\\beta (R_\\tau v)(x)\n",
    "$$\n",
    "\n",
    "with $K = A_{MIN}\\circ R_\\tau$. Under the same assumption, prove that $K$ is globally stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99713a-0af4-408a-ab47-27115d453419",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Since we have shown that $A_{MIN}$ is Blackwell aggregator, and $R_\\tau$ is constant-subadditive, hence, we have, $K_\\tau$ is globally stable because it is a contraction on $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d543ca-08e7-4ab3-be20-03837af0ac9a",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.20\n",
    "\n",
    "Confirm that $L$ is irreducible when $b\\gg 0$ and $P$ is irreducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd6cff0-32fe-48ba-aae4-4b3de1914e75",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Since $P$ is irreducible, then $P\\ge 0$ and $\\sum_{k=0}^\\infty P^k \\gg 0$.\n",
    "\n",
    "Since $b\\gg 0$, we have $L = bP \\ge 0$ and $\\sum_{k=0}^\\infty (bP)^k \\gg 0$. Hence $L$ is irreducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d627f58-ff63-4735-9c21-7b257a00cd8f",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.21.\n",
    "\n",
    "Show that $K$ is a self-map on $V = (0,\\infty)^X$, and assume $h,b\\in V$ and $P$ is irreducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a85f62-b676-42aa-839a-bcf0bccda0bd",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "Kv = \\{h+b[Pv^\\gamma]^{\\alpha/\\gamma}\\}^{1/\\alpha}\n",
    "$$\n",
    "\n",
    "Let $v\\in V$. \n",
    "\n",
    "By $h,b\\in V$ and $P$ irreducible hence increasing, $Kv\\in V$.\n",
    "\n",
    "Hence, $K$ is a self-map on $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f202e-ff86-4471-91b1-8de506416af5",
   "metadata": {},
   "source": [
    "### EXERCISE 7.3.22.\n",
    "\n",
    "Prove $(V,K)$ and $(V,\\hat K)$ are topologically conjugated under $\\Phi v =v^\\gamma$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef21236-9e45-411e-927e-e00f6369abd4",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "\\hat K v = \\{h + (Av)^{1/\\theta}\\}^\\theta\n",
    "$$\n",
    "\n",
    "where $(Av)(x)=b(x)^\\theta\\sum_{x'}v(x')P(x,x')$. \n",
    "\n",
    "$$\n",
    "Kv = \\{h+b[Pv^\\gamma]^{\\alpha/\\gamma}\\}^{1/\\alpha}\n",
    "$$\n",
    "\n",
    "We want to show that\n",
    "\n",
    "$$\n",
    "\\Phi K v = \\hat K \\Phi v\n",
    "$$\n",
    "\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "\\Phi K v = \\{h + b(Pv^\\gamma)^{\\alpha/\\gamma}\\}^{\\gamma/\\alpha} = \\hat K \\Phi v\n",
    "$$\n",
    "\n",
    "Moreover, since $\\Phi$ is a homeomorphism, we proved this claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf6da8-61c1-46c4-8a82-81c7cde3145f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
