{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0563a2-9a93-4841-99d7-bb699761d93c",
   "metadata": {},
   "source": [
    "# Chapter 3 Markov Dynamics Reading Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1b79e-4e0d-4f8c-9640-6f0d54a0ac50",
   "metadata": {},
   "source": [
    "Three subsections:\n",
    "\n",
    "1. Foundations: Markov chains, stationarity and ergodicity, approximation\n",
    "2. Conditional Expectations: mathematical expectations, geometric sums\n",
    "3. Job search revisited: Job search with Markov state, Job search with separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c83513-8564-44c2-8ee0-5bcabb8773f7",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed834d-244b-479d-a3d4-4686765a34de",
   "metadata": {},
   "source": [
    "**Definition (Markov chain on State Space X)**\n",
    "\n",
    "Let $(X_t):= (X_t)_{t\\ge 0}$ be a sequence of random variables taking values in $X$ and call $(X_t)$ a **Markov chain on state space $X$** if there exists a $P\\in\\mathscr{M}(\\mathbb{R}^X)$ such that\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\{X_{t+1} = x'|X_0,X_1,\\cdots,X_t\\}=P(X_t,x') \\,\\,\\,\\forall t\\ge 0, x'\\in X \\tag{P-Markov}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fdad60-9759-4d34-baaa-b4377b44533a",
   "metadata": {},
   "source": [
    "**Definition (P-Markov)**\n",
    "\n",
    "We call $(X_t)$ a $P$-Markov when the above condition holds.\n",
    "\n",
    "\n",
    "**Definition (initial distribution)**\n",
    "\n",
    "We call $X_0$ or its distribution $\\psi_0$ the **initial condition** of $(X_t)$ depending on the context.\n",
    "\n",
    "**Definition (transition matrix)**\n",
    "\n",
    "$P$ is also called the **transition matrix** of the Markov chain.\n",
    "\n",
    "**Definition (k-step transition matrix)**\n",
    "\n",
    "Since $\\mathscr{M}(\\mathbb{R}^X)$ is closed under multiplication, $P^k \\in\\mathscr{M}(\\mathbb{R}^X)$ for all $k\\in\\mathbb{N}$. In this context, $P^k$ is called the $k$-**step transition matrix** correponding to $P$.\n",
    "\n",
    "The $k$-step transition matrix has the following interpretation: \n",
    "\n",
    "If $(X_t)$ is $P$-Markov, then for any $t,k\\in\\mathbb{Z}_+$, and $x,x'\\in X$,\n",
    "\n",
    "$$\n",
    "P^k(x,x') = \\mathbb{P}\\{X_{t+k}=x'|X_t=x\\}\n",
    "$$\n",
    "\n",
    "Thus, $P^k$ provides the $k$-step transition probabilities for the $P$-Markov chain $(X_t)$.\n",
    "\n",
    "$P^k(x,x')$ denotes the $(x,x')$-th element of the matrix representation of $P^k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca1d46-0df8-461f-b4e6-5877cd0d5d15",
   "metadata": {},
   "source": [
    "**Definition (absorbing state)**\n",
    "Once entered, the probability of ever leaving the state is zero. A subset $Y$ of $X$ with this property is called an **absorbing state**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b4e81-a612-4152-83c4-2ea041aaa1dd",
   "metadata": {},
   "source": [
    "**Definition (stationary)**\n",
    "\n",
    "A marginal distribution $\\psi^*\\in\\mathcal{D}(X)$ is called **stationary** for $P$ if \n",
    "\n",
    "$$\n",
    "\\sum_{x\\in X} P(x,x')\\psi^*(x) = \\psi^*(x') \n",
    "$$\n",
    "\n",
    "for all $x'\\in X$.\n",
    "\n",
    "In vector form, we have,\n",
    "\n",
    "$$\n",
    "\\psi^* P =\\psi^*\n",
    "$$\n",
    "\n",
    "Hence, if $\\psi^*$ is stationary and $X_t$ has distribution $\\psi^*$, then so does $X_{t+k}$ for all $k\\ge 0$.\n",
    "\n",
    "When $P$ is irreducible, there exists a unique stationary distribution $\\psi^*$, such that\n",
    "\n",
    "$$\n",
    "\\psi P^t \\to \\psi^*\n",
    "$$\n",
    "\n",
    "for any $\\psi\\in\\mathcal{D}(X)$. \n",
    "\n",
    "Thus, the operator $P$ when understood as the mapping from $\\psi\\mapsto \\psi P$ is globally stable on $\\mathcal{D}(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd73f8b0-703c-47a7-b218-4dd2e9a3432d",
   "metadata": {},
   "source": [
    "## Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74cf06-432e-458e-b366-5e8717224549",
   "metadata": {},
   "source": [
    "**Lemma (Irreducibility)**\n",
    "\n",
    "Given $P\\in\\mathscr{M}(\\mathbb{R}^X)$, the following statements are equivalent:\n",
    "\n",
    "1. $P$ is irreducible\n",
    "\n",
    "2. If $(X_t)$ is $P$-Markov and $x,x'\\in X$, then there exists $k\\ge 0$ such that\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\{X_k=x'|X_0=x\\}>0\n",
    "$$\n",
    "\n",
    "Thus, **irreducibility of P means that the P-Markov chain eventually visits all states from any other states with positive probability**.\n",
    "\n",
    "(See Python Code fold for test of irreducibility using `quantecon` packages)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6b204-929c-4b69-936d-9af3d506af55",
   "metadata": {},
   "source": [
    "### Ergodicity Theorem\n",
    "\n",
    "If $P$ is irreducible with stationary distribution $\\psi^*$, then, for any $P$-Markov chain $(X_t)$  and any $x\\in X$, we have,\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left\\{\\lim_{k\\to\\infty} \\frac{1}{k} \\sum_{t=0}^{k-1} \\mathbb{1}\\{X_t=x\\}=\\psi^*(x)\\right\\} = 1\n",
    "$$\n",
    "\n",
    "This tells us that for almost every $P$-Markov we generate, **the fraction of time the chain spends in any given state is, in the limit, equal to the probability assigned to that state by the stationary distribution**.\n",
    "\n",
    "**Markov chains with this property are called to be ergodic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41911b3-8400-478b-b12e-dab8a78e947e",
   "metadata": {},
   "source": [
    "## Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532e2bd-bcb1-4401-bdce-b3dae2c55169",
   "metadata": {},
   "source": [
    "The definition of a Markov chain says two things:\n",
    "\n",
    "1. When updating to $X_{t+1}$ from $X_t$, **earlier states are not required**.\n",
    "\n",
    "2. $P$ **encodes all of the information required to perform the update**, given the current state $X_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad706d-4a3e-4dc5-926c-2026f66a77d3",
   "metadata": {},
   "source": [
    "### Think about Markov chain in algorithmic way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e15885-7a48-4856-9c98-650c3c53d288",
   "metadata": {},
   "source": [
    "Fix $P\\in\\mathscr{M}(\\mathbb{R}^X)$ and let $\\psi_0$ be an element of $\\mathcal{D}(X)$. \n",
    "\n",
    "Now generate $(X_t)$ using the following algorithm, the resulting sequence is $P$-Markov with inital distribution $\\psi_0$.\n",
    "\n",
    "**Algorithm: Generate of $P$-Markov $(X_t)$ with initial condition $\\psi_0$**\n",
    "\n",
    "$t\\gets 0$\n",
    "\n",
    "$X_t\\gets$ a draw from $\\psi_0$\n",
    "\n",
    "**while** $t<\\infty$ **do**\n",
    "\n",
    "$X_{t+1}\\gets$ a draw from the distribution $P(X_t, \\cdot)$\n",
    "    \n",
    "$t\\gets t+1$\n",
    "\n",
    "**end**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5767e8-6fdb-46c2-892b-0d8d2c95dd15",
   "metadata": {},
   "source": [
    "### Application: S-s dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd74bb-2154-4346-9c8f-1ba74633f06c",
   "metadata": {},
   "source": [
    "Consider a firm whose inventory of some products follows a $S-s$ dynamics, meaning that the firm waits until its inventory falls below some level $s>0$ and then immediately replenishes by ordering $S$ units.\n",
    "\n",
    "This pattern of decisions can be rationalized if **ordering requires paying a fixed cost**. The $S-s$ behavior is optimal in **a setting where fixed costs exists and the firm's aim is to maximize its present value**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe88f4-0e6b-41b8-844d-2837c083cb31",
   "metadata": {},
   "source": [
    "To represent $S-s$ dynamics, we suppose that a firm's inventory $(X_t)_{t\\ge 0}$ of a given product obeys,\n",
    "\n",
    "$$\n",
    "X_{t+1} = \\max\\{X_t-D_{t+1},0\\} + S\\mathbb{1}\\{X_t\\le s\\}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $(D_t)_{t\\ge 1}$ is an exogenous IID demand process with $D_t=_d\\varphi\\in\\mathcal{D}(\\mathbb{Z}_+)$ for all $t$\n",
    "\n",
    "- $S$ is the quantity ordered when $X_t\\le s$.\n",
    "\n",
    "- The distribution $\\varphi$ of demand, we take geometric distribution, so that \n",
    "\n",
    "$$\n",
    "\\varphi(d) = \\mathbb{P}\\{D_t=d\\} = p(1-p)^d,\\,\\,d\\in\\mathbb{Z}_+\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170b684f-995b-48c4-ab0c-1d54643cadf8",
   "metadata": {},
   "source": [
    "If we define $h(x,d):= \\max\\{x-d,0\\}+S\\mathbb{1}\\{x\\le s\\}$, so that $X_{t+1} = h(X_t,D_{t+1})$ for all $t$, then the transition matrix can be expressed as\n",
    "\n",
    "$$\n",
    "P(x,x') = \\mathbb{P}\\{h(x,D_{t+1})=x'\\} = \\sum_{d\\ge 0}\\mathbb{1}\\{h(x,d)=x'\\}\\varphi(d)\n",
    "$$\n",
    "\n",
    "for all $(x,x')\\in X\\times X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc55ce5-85df-44eb-ad1e-7b238deabb0b",
   "metadata": {},
   "source": [
    "(For Python code, see Python code folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d64a57-d032-4529-bef4-d961e801ee56",
   "metadata": {},
   "source": [
    "## Stationarity and Ergodicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb4972-cf73-4582-a409-f7dcfa839bf3",
   "metadata": {},
   "source": [
    "Fix $P\\in \\mathscr{M}(\\mathbb{R}^X)$ and let $(X_t)$ be a $P$-Markov chain. \n",
    "\n",
    "Let $\\psi_t$ be the distribution of $X_t$. \n",
    "\n",
    "Marginal distribution $\\psi_t$ evolves according to\n",
    "\n",
    "$$\n",
    "\\psi_{t+1} (x') = \\sum_{x\\in X} P(x,x')\\psi_t(x)\n",
    "$$\n",
    "\n",
    "for all $x'\\in X, t\\ge 0$.\n",
    "\n",
    "\n",
    "Why?\n",
    "\n",
    "USE LTP: we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\psi_{t+1}(x') &= \\mathbb{P}\\{X_{t+1} = x'\\}\\\\\n",
    "&= \\sum_{x\\in X}\\mathbb{P}\\{X_{t+1}=x'|X_t=x\\}\\mathbb{P}\\{X_t = x\\} \\tag{LTP}\\\\\n",
    "&= \\sum_{x\\in X}\\mathbb{P}\\{X_{t+1}=x'|X_t=x\\}\\psi_t(x)\\\\\n",
    "&= \\sum_{x\\in X}P(x,x')\\psi_t(x)\\\\\n",
    "&= (\\psi_t P) (x')\n",
    "\\end{align*}\n",
    "\n",
    "Hence, we have\n",
    "\n",
    "$$\n",
    "\\psi_{t+1} = \\psi_t P\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c637bc-b922-43f5-8bf8-9cd5ca3a7039",
   "metadata": {},
   "source": [
    "**This tells us that dynamics of marginal distributions for Markov chains are generated by deterministic linear difference equations in distribution space.**\n",
    "\n",
    "This is remarkable because the dynamics drive $(X_t)$ are stochastic and can be arbitrarily nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3c5f6-7fd0-4c8b-842e-1c9483eb260a",
   "metadata": {},
   "source": [
    "Iterating the above equality, we get,\n",
    "\n",
    "$$\n",
    "\\psi_t = \\psi_0 P^t\n",
    "$$\n",
    "\n",
    "Hence, we have,\n",
    "\n",
    "$$\n",
    "(X_t)_{t\\ge 0} \\,\\,\\text{is P-Markov with $X_0=_d \\psi_0\\implies X_t=_d\\psi_t=\\psi_0 P^t$ for all $t\\ge 0$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d635326-25af-43dc-a248-1629081e9615",
   "metadata": {},
   "source": [
    "**Every irreducible $P\\in\\mathscr{M}(\\mathbb{R}^X)$** has exactly one stationary distribution $\\psi^*\\in\\mathcal{D}(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc270c56-5e13-4333-b0ca-68900a132812",
   "metadata": {},
   "source": [
    "### Application: Day Laborer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e245872-0eeb-4a3e-a812-06f127223b46",
   "metadata": {},
   "source": [
    "Suppose a day laborer is either unemployed $X_t= 1$ or employed $X_t = 2$ in each period, with following transition matrix:\n",
    "\n",
    "$$\n",
    "P = \\begin{bmatrix}\n",
    "1-\\alpha & \\alpha\\\\\n",
    "\\beta & 1-\\beta\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "See python code for update from $X_t$ to $X_{t+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5dcc8-f3c2-4029-b12d-e26f392fe765",
   "metadata": {},
   "source": [
    "## Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1cfa5-651c-4e5f-b707-2205e5a42ea4",
   "metadata": {},
   "source": [
    "To simplify numerical calculation, we approximate a continuous state Markov process with a Markov chain. \n",
    "\n",
    "For example, a **linear Gaussian AR(1)** model, where $(X_t)$ evolves,\n",
    "\n",
    "$$\n",
    "X_{t+1} = \\beta X_t + b + \\nu \\varepsilon_{t+1},\\,\\,\\,|\\rho|<1,\\,\\,\\,(\\varepsilon_t)\\sim_{IID} N(0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f37a1a-cb9b-4095-9961-237e0b1272b7",
   "metadata": {},
   "source": [
    "The model has a unique **stationary distribution** $\\psi^*$ given by\n",
    "\n",
    "$$\n",
    "\\psi^* = N(\\mu_x,\\sigma_x^2), \\mu_x = \\dfrac{b}{1-\\rho}, \\sigma_x^2 = \\dfrac{\\nu^2}{1-\\rho^2}\n",
    "$$\n",
    "\n",
    "This means that \n",
    "\n",
    "$$\n",
    "X_t=_d\\psi^*, X_{t+1} = \\rho X_t+b+\\nu\\varepsilon_{t+1}\\implies X_{t+1}=_d\\psi^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2755a-df74-4713-a9ee-00a19f18f76a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
