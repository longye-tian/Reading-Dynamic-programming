{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0563a2-9a93-4841-99d7-bb699761d93c",
   "metadata": {},
   "source": [
    "# Chapter 3 Markov Dynamics Reading Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1b79e-4e0d-4f8c-9640-6f0d54a0ac50",
   "metadata": {},
   "source": [
    "Three subsections:\n",
    "\n",
    "1. Foundations: Markov chains, stationarity and ergodicity, approximation\n",
    "2. Conditional Expectations: mathematical expectations, geometric sums\n",
    "3. Job search revisited: Job search with Markov state, Job search with separation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c83513-8564-44c2-8ee0-5bcabb8773f7",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed834d-244b-479d-a3d4-4686765a34de",
   "metadata": {},
   "source": [
    "**Definition (Markov chain on State Space X)**\n",
    "\n",
    "Let $(X_t):= (X_t)_{t\\ge 0}$ be a sequence of random variables taking values in $X$ and call $(X_t)$ a **Markov chain on state space $X$** if there exists a $P\\in\\mathscr{M}(\\mathbb{R}^X)$ such that\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\{X_{t+1} = x'|X_0,X_1,\\cdots,X_t\\}=P(X_t,x') \\,\\,\\,\\forall t\\ge 0, x'\\in X \\tag{P-Markov}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fdad60-9759-4d34-baaa-b4377b44533a",
   "metadata": {},
   "source": [
    "**Definition (P-Markov)**\n",
    "\n",
    "We call $(X_t)$ a $P$-Markov when the above condition holds.\n",
    "\n",
    "\n",
    "**Definition (initial distribution)**\n",
    "\n",
    "We call $X_0$ or its distribution $\\psi_0$ the **initial condition** of $(X_t)$ depending on the context.\n",
    "\n",
    "**Definition (transition matrix)**\n",
    "\n",
    "$P$ is also called the **transition matrix** of the Markov chain.\n",
    "\n",
    "**Definition (k-step transition matrix)**\n",
    "\n",
    "Since $\\mathscr{M}(\\mathbb{R}^X)$ is closed under multiplication, $P^k \\in\\mathscr{M}(\\mathbb{R}^X)$ for all $k\\in\\mathbb{N}$. In this context, $P^k$ is called the $k$-**step transition matrix** correponding to $P$.\n",
    "\n",
    "The $k$-step transition matrix has the following interpretation: \n",
    "\n",
    "If $(X_t)$ is $P$-Markov, then for any $t,k\\in\\mathbb{Z}_+$, and $x,x'\\in X$,\n",
    "\n",
    "$$\n",
    "P^k(x,x') = \\mathbb{P}\\{X_{t+k}=x'|X_t=x\\}\n",
    "$$\n",
    "\n",
    "Thus, $P^k$ provides the $k$-step transition probabilities for the $P$-Markov chain $(X_t)$.\n",
    "\n",
    "$P^k(x,x')$ denotes the $(x,x')$-th element of the matrix representation of $P^k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca1d46-0df8-461f-b4e6-5877cd0d5d15",
   "metadata": {},
   "source": [
    "**Definition (absorbing state)**\n",
    "Once entered, the probability of ever leaving the state is zero. A subset $Y$ of $X$ with this property is called an **absorbing state**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b4e81-a612-4152-83c4-2ea041aaa1dd",
   "metadata": {},
   "source": [
    "**Definition (stationary)**\n",
    "\n",
    "A marginal distribution $\\psi^*\\in\\mathcal{D}(X)$ is called **stationary** for $P$ if \n",
    "\n",
    "$$\n",
    "\\sum_{x\\in X} P(x,x')\\psi^*(x) = \\psi^*(x') \n",
    "$$\n",
    "\n",
    "for all $x'\\in X$.\n",
    "\n",
    "In vector form, we have,\n",
    "\n",
    "$$\n",
    "\\psi^* P =\\psi^*\n",
    "$$\n",
    "\n",
    "Hence, if $\\psi^*$ is stationary and $X_t$ has distribution $\\psi^*$, then so does $X_{t+k}$ for all $k\\ge 0$.\n",
    "\n",
    "When $P$ is irreducible, there exists a unique stationary distribution $\\psi^*$, such that\n",
    "\n",
    "$$\n",
    "\\psi P^t \\to \\psi^*\n",
    "$$\n",
    "\n",
    "for any $\\psi\\in\\mathcal{D}(X)$. \n",
    "\n",
    "Thus, the operator $P$ when understood as the mapping from $\\psi\\mapsto \\psi P$ is globally stable on $\\mathcal{D}(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c94bb8f-1e52-443f-94a0-14fe7f73c2a5",
   "metadata": {},
   "source": [
    "**Definition (monotone increasing)**\n",
    "Let $X$ be a finite set partially ordered by $\\precsim$. \n",
    "\n",
    "A Markov operator $P\\in\\mathscr{M}(\\mathbb{R}^X)$ is called **monotone increasing** if\n",
    "\n",
    "$$\n",
    "x,y\\in X, x\\precsim y\\implies P(x,\\cdot)\\precsim_F P(y,\\cdot)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd73f8b0-703c-47a7-b218-4dd2e9a3432d",
   "metadata": {},
   "source": [
    "## Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74cf06-432e-458e-b366-5e8717224549",
   "metadata": {},
   "source": [
    "**Lemma (Irreducibility)**\n",
    "\n",
    "Given $P\\in\\mathscr{M}(\\mathbb{R}^X)$, the following statements are equivalent:\n",
    "\n",
    "1. $P$ is irreducible\n",
    "\n",
    "2. If $(X_t)$ is $P$-Markov and $x,x'\\in X$, then there exists $k\\ge 0$ such that\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\{X_k=x'|X_0=x\\}>0\n",
    "$$\n",
    "\n",
    "Thus, **irreducibility of P means that the P-Markov chain eventually visits all states from any other states with positive probability**.\n",
    "\n",
    "(See Python Code fold for test of irreducibility using `quantecon` packages)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6b204-929c-4b69-936d-9af3d506af55",
   "metadata": {},
   "source": [
    "### Ergodicity Theorem\n",
    "\n",
    "If $P$ is irreducible with stationary distribution $\\psi^*$, then, for any $P$-Markov chain $(X_t)$  and any $x\\in X$, we have,\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left\\{\\lim_{k\\to\\infty} \\frac{1}{k} \\sum_{t=0}^{k-1} \\mathbb{1}\\{X_t=x\\}=\\psi^*(x)\\right\\} = 1\n",
    "$$\n",
    "\n",
    "This tells us that for almost every $P$-Markov we generate, **the fraction of time the chain spends in any given state is, in the limit, equal to the probability assigned to that state by the stationary distribution**.\n",
    "\n",
    "**Markov chains with this property are called to be ergodic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94ae1c-8408-4700-a805-a2832405a259",
   "metadata": {},
   "source": [
    "### Lemma 3.2.1. (EPV)\n",
    "\n",
    "If $\\beta<1$, then $I-\\beta P$ is invertible and\n",
    "\n",
    "$$\n",
    "v = \\sum_{t=0}^\\infty (\\beta P)^t h = (I-\\beta P)^{-1} h\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f0894-55a7-4142-ab83-cf9c9ff93e5e",
   "metadata": {},
   "source": [
    "### Lemma 3.3.1.($v^*$ and P monotone increasing)\n",
    "\n",
    "$v^*$ is increasing on $(W,\\le)$ whenever $P$ is monotone increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41911b3-8400-478b-b12e-dab8a78e947e",
   "metadata": {},
   "source": [
    "## Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532e2bd-bcb1-4401-bdce-b3dae2c55169",
   "metadata": {},
   "source": [
    "The definition of a Markov chain says two things:\n",
    "\n",
    "1. When updating to $X_{t+1}$ from $X_t$, **earlier states are not required**.\n",
    "\n",
    "2. $P$ **encodes all of the information required to perform the update**, given the current state $X_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad706d-4a3e-4dc5-926c-2026f66a77d3",
   "metadata": {},
   "source": [
    "### Think about Markov chain in algorithmic way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e15885-7a48-4856-9c98-650c3c53d288",
   "metadata": {},
   "source": [
    "Fix $P\\in\\mathscr{M}(\\mathbb{R}^X)$ and let $\\psi_0$ be an element of $\\mathcal{D}(X)$. \n",
    "\n",
    "Now generate $(X_t)$ using the following algorithm, the resulting sequence is $P$-Markov with inital distribution $\\psi_0$.\n",
    "\n",
    "**Algorithm: Generate of $P$-Markov $(X_t)$ with initial condition $\\psi_0$**\n",
    "\n",
    "$t\\gets 0$\n",
    "\n",
    "$X_t\\gets$ a draw from $\\psi_0$\n",
    "\n",
    "**while** $t<\\infty$ **do**\n",
    "\n",
    "$X_{t+1}\\gets$ a draw from the distribution $P(X_t, \\cdot)$\n",
    "    \n",
    "$t\\gets t+1$\n",
    "\n",
    "**end**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5767e8-6fdb-46c2-892b-0d8d2c95dd15",
   "metadata": {},
   "source": [
    "### Application: S-s dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd74bb-2154-4346-9c8f-1ba74633f06c",
   "metadata": {},
   "source": [
    "Consider a firm whose inventory of some products follows a $S-s$ dynamics, meaning that the firm waits until its inventory falls below some level $s>0$ and then immediately replenishes by ordering $S$ units.\n",
    "\n",
    "This pattern of decisions can be rationalized if **ordering requires paying a fixed cost**. The $S-s$ behavior is optimal in **a setting where fixed costs exists and the firm's aim is to maximize its present value**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe88f4-0e6b-41b8-844d-2837c083cb31",
   "metadata": {},
   "source": [
    "To represent $S-s$ dynamics, we suppose that a firm's inventory $(X_t)_{t\\ge 0}$ of a given product obeys,\n",
    "\n",
    "$$\n",
    "X_{t+1} = \\max\\{X_t-D_{t+1},0\\} + S\\mathbb{1}\\{X_t\\le s\\}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $(D_t)_{t\\ge 1}$ is an exogenous IID demand process with $D_t=_d\\varphi\\in\\mathcal{D}(\\mathbb{Z}_+)$ for all $t$\n",
    "\n",
    "- $S$ is the quantity ordered when $X_t\\le s$.\n",
    "\n",
    "- The distribution $\\varphi$ of demand, we take geometric distribution, so that \n",
    "\n",
    "$$\n",
    "\\varphi(d) = \\mathbb{P}\\{D_t=d\\} = p(1-p)^d,\\,\\,d\\in\\mathbb{Z}_+\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170b684f-995b-48c4-ab0c-1d54643cadf8",
   "metadata": {},
   "source": [
    "If we define $h(x,d):= \\max\\{x-d,0\\}+S\\mathbb{1}\\{x\\le s\\}$, so that $X_{t+1} = h(X_t,D_{t+1})$ for all $t$, then the transition matrix can be expressed as\n",
    "\n",
    "$$\n",
    "P(x,x') = \\mathbb{P}\\{h(x,D_{t+1})=x'\\} = \\sum_{d\\ge 0}\\mathbb{1}\\{h(x,d)=x'\\}\\varphi(d)\n",
    "$$\n",
    "\n",
    "for all $(x,x')\\in X\\times X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc55ce5-85df-44eb-ad1e-7b238deabb0b",
   "metadata": {},
   "source": [
    "(For Python code, see Python code folder)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d64a57-d032-4529-bef4-d961e801ee56",
   "metadata": {},
   "source": [
    "## Stationarity and Ergodicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb4972-cf73-4582-a409-f7dcfa839bf3",
   "metadata": {},
   "source": [
    "Fix $P\\in \\mathscr{M}(\\mathbb{R}^X)$ and let $(X_t)$ be a $P$-Markov chain. \n",
    "\n",
    "Let $\\psi_t$ be the distribution of $X_t$. \n",
    "\n",
    "Marginal distribution $\\psi_t$ evolves according to\n",
    "\n",
    "$$\n",
    "\\psi_{t+1} (x') = \\sum_{x\\in X} P(x,x')\\psi_t(x)\n",
    "$$\n",
    "\n",
    "for all $x'\\in X, t\\ge 0$.\n",
    "\n",
    "\n",
    "Why?\n",
    "\n",
    "USE LTP: we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\psi_{t+1}(x') &= \\mathbb{P}\\{X_{t+1} = x'\\}\\\\\n",
    "&= \\sum_{x\\in X}\\mathbb{P}\\{X_{t+1}=x'|X_t=x\\}\\mathbb{P}\\{X_t = x\\} \\tag{LTP}\\\\\n",
    "&= \\sum_{x\\in X}\\mathbb{P}\\{X_{t+1}=x'|X_t=x\\}\\psi_t(x)\\\\\n",
    "&= \\sum_{x\\in X}P(x,x')\\psi_t(x)\\\\\n",
    "&= (\\psi_t P) (x')\n",
    "\\end{align*}\n",
    "\n",
    "Hence, we have\n",
    "\n",
    "$$\n",
    "\\psi_{t+1} = \\psi_t P\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c637bc-b922-43f5-8bf8-9cd5ca3a7039",
   "metadata": {},
   "source": [
    "**This tells us that dynamics of marginal distributions for Markov chains are generated by deterministic linear difference equations in distribution space.**\n",
    "\n",
    "This is remarkable because the dynamics drive $(X_t)$ are stochastic and can be arbitrarily nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3c5f6-7fd0-4c8b-842e-1c9483eb260a",
   "metadata": {},
   "source": [
    "Iterating the above equality, we get,\n",
    "\n",
    "$$\n",
    "\\psi_t = \\psi_0 P^t\n",
    "$$\n",
    "\n",
    "Hence, we have,\n",
    "\n",
    "$$\n",
    "(X_t)_{t\\ge 0} \\,\\,\\text{is P-Markov with $X_0=_d \\psi_0\\implies X_t=_d\\psi_t=\\psi_0 P^t$ for all $t\\ge 0$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d635326-25af-43dc-a248-1629081e9615",
   "metadata": {},
   "source": [
    "**Every irreducible $P\\in\\mathscr{M}(\\mathbb{R}^X)$** has exactly one stationary distribution $\\psi^*\\in\\mathcal{D}(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc270c56-5e13-4333-b0ca-68900a132812",
   "metadata": {},
   "source": [
    "### Application: Day Laborer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e245872-0eeb-4a3e-a812-06f127223b46",
   "metadata": {},
   "source": [
    "Suppose a day laborer is either unemployed $X_t= 1$ or employed $X_t = 2$ in each period, with following transition matrix:\n",
    "\n",
    "$$\n",
    "P = \\begin{bmatrix}\n",
    "1-\\alpha & \\alpha\\\\\n",
    "\\beta & 1-\\beta\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "See python code for update from $X_t$ to $X_{t+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5dcc8-f3c2-4029-b12d-e26f392fe765",
   "metadata": {},
   "source": [
    "## Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e1cfa5-651c-4e5f-b707-2205e5a42ea4",
   "metadata": {},
   "source": [
    "To simplify numerical calculation, we approximate a continuous state Markov process with a Markov chain. \n",
    "\n",
    "For example, a **linear Gaussian AR(1)** model, where $(X_t)$ evolves,\n",
    "\n",
    "$$\n",
    "X_{t+1} = \\beta X_t + b + \\nu \\varepsilon_{t+1},\\,\\,\\,|\\rho|<1,\\,\\,\\,(\\varepsilon_t)\\sim_{IID} N(0,1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f37a1a-cb9b-4095-9961-237e0b1272b7",
   "metadata": {},
   "source": [
    "The model has a unique **stationary distribution** $\\psi^*$ given by\n",
    "\n",
    "$$\n",
    "\\psi^* = N(\\mu_x,\\sigma_x^2), \\mu_x = \\dfrac{b}{1-\\rho}, \\sigma_x^2 = \\dfrac{\\nu^2}{1-\\rho^2}\n",
    "$$\n",
    "\n",
    "This means that \n",
    "\n",
    "$$\n",
    "X_t=_d\\psi^*, X_{t+1} = \\rho X_t+b+\\nu\\varepsilon_{t+1}\\implies X_{t+1}=_d\\psi^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5302b-2213-4feb-816e-4b736568410d",
   "metadata": {},
   "source": [
    "## Tauchen's method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fef8f-1aa3-4083-8f07-80f0027ed972",
   "metadata": {},
   "source": [
    "We use **Tauchen's method** to **discretize** the AR(1) process.\n",
    "\n",
    "STEP:\n",
    "\n",
    "1. Choose \n",
    "   - $n$ as the number of states for the discrete approximation \n",
    "   - $m$ as an integer that sets the width of the state space.\n",
    "2. Create a state space $X$ as an equispaced grid that brackets the stationary mean on both sides by $m$ standard deviations, i.e.,\n",
    "   - $X = \\{x_1,\\cdots,x_n\\}\\subset \\mathbb{R}$\n",
    "   - set $x_1 = -m\\sigma_x$\n",
    "   - set $x_n = m\\sigma_x$\n",
    "   - set $x_{i+1} = x_1+s, s=\\dfrac{x_n-x_1}{n-1}, i\\in[n-1]$\n",
    "   \n",
    "3. Create an $n\\times n$ matrix $P$ that approximates the AR(1) dynamics. For $i,j\\in[n]$,\n",
    "   - if $j=1$, then set $P(x_i,x_j)= F(x_1-\\rho x_i + s/2)$\n",
    "   - if $j=n$, then set $P(x_i,x_j)= 1-F(x_n-\\rho x_i-s/2)$\n",
    "   - Otherwise, set $P(x_i,x_j) = F(x_j-\\rho x_i + s/2) -F(x_j-\\rho x_i-s/2)$\n",
    "   \n",
    "If $b\\neq 0$,  then we shift the state space to center it on the mean $\\mu_x$ of the stationary distribution $N(\\mu_x,\\sigma_x^2)$. This is done by replacing $x_i$ with $x_i+\\mu_x$ for each $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647fb5ae-1228-4afb-8918-d18925bc8bbb",
   "metadata": {},
   "source": [
    "## Conditional Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a830600f-799b-4890-9e21-7cf5a2243e12",
   "metadata": {},
   "source": [
    "Fix $P\\in\\mathscr{M}(\\mathbb{R}^X)$. For each $h\\in\\mathbb{R}^X$, we define,\n",
    "\n",
    "$$\n",
    "(Ph)(x) = \\sum_{x'\\in X}h(x')P(x,x')\\tag{$x\\in X$}\n",
    "$$\n",
    "\n",
    "Note that $P(x,\\cdot)$ is the distribution of $X_{t+1}$ given $X_t=x$, we can write,\n",
    "\n",
    "$$\n",
    "(Ph)(x) = \\mathbb{E}[h(X_{t+1})|X_t=x]\n",
    "$$\n",
    "\n",
    "where $(X_t)$ is any $P$-Markov chain on $X$. \n",
    "\n",
    "(In terms of matrix algebra, viewing $h$ has an $n\\times 1$ column vector, the expression $(Ph)(x)$ is one element of the vector $Ph$ obtained by premultiplying $h$ by $P$)\n",
    "\n",
    "\n",
    "For powers of $P$, we have,\n",
    "\n",
    "$$\n",
    "(P^kh)(x)= \\sum_{x'\\in X}h(x')P^k(x,x') = \\mathbb{E}[h(X_{t+k})=x'|X_t=x]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23026a-a06e-4adc-a2b9-a8137f17d76c",
   "metadata": {},
   "source": [
    "**Every constant function is a fixed point of $P$**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3fc9b-7edc-483b-a83f-071d64df57be",
   "metadata": {},
   "source": [
    "## Law of Iterated Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a46ace-a34a-498f-b783-d7c51710b132",
   "metadata": {},
   "source": [
    "Let $(X_t)$ be $P$-Markov with $X_0=_d\\psi_0$. Fix $t,k\\in\\mathbb{N}$.\n",
    "\n",
    "Set $\\mathbb{E}_t:= \\mathbb{E}[\\cdot|X_t]$. We claim that \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\mathbb{E}_t[h(X_{t+k})]] = \\mathbb{E}[h(X_{t+k})]\n",
    "$$\n",
    "\n",
    "for any $h\\in\\mathbb{R}^X$.\n",
    "\n",
    "To see this, recall that $\\mathbb{E}[h(X_{t+1})|X_t=x]=(P^kh)(x)$. \n",
    "\n",
    "Hence, $\\mathbb{E}[h(X_{t+1})|X_t]=(P^k h)(X_t)$.\n",
    "\n",
    "Therefore, \n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\mathbb{E}_t[h(X_{t+1})]] = \\mathbb{E}[(P^kh)(X_t)]=\\sum_{x'\\in X}(P^kh)(x')\\psi_t(x') = \\sum_{x'\\in X}(P^kh)(x')(\\psi_0P^t)(x')\n",
    "$$\n",
    "\n",
    "Since $\\psi_0 P^t$ is a row vector, we can write the last expression as\n",
    "\n",
    "$$\n",
    "\\psi_0P^tP^k h = \\psi_0P^{t+k}h = \\psi_{t+k}h = \\mathbb{E}h(X_{t+k})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc442241-d0c3-4a89-b37f-21d2d94389f1",
   "metadata": {},
   "source": [
    "### Monotone Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7232f15-e068-45d2-8959-bc25a28ea57a",
   "metadata": {},
   "source": [
    "Let $X$ be a finite set partially ordered by $\\precsim$. \n",
    "\n",
    "A Markov operator $P\\in\\mathscr{M}(\\mathbb{R}^X)$ is called **monotone increasing** if\n",
    "\n",
    "$$\n",
    "x,y\\in X, x\\precsim y\\implies P(x,\\cdot)\\precsim_F P(y,\\cdot)\n",
    "$$\n",
    "\n",
    "Thus, $P$ is monotone increasing if shifting up the current state shifts up the next period state, in the sense that its distribution increases in the stochastic dominance ordering.\n",
    "\n",
    "**Monotonicity of Markov operators is related to positive autocorrelation**.\n",
    "\n",
    "Consider the AR(1) model, $X_{t+1} = \\rho X_t + \\sigma\\varepsilon_{t+1}$ and suppose we apply Tauchen discretization, mapping the parameters $\\rho, \\sigma$ and a discretization size $n$ into a Markov operator $P$ on state space $X=\\{x_1,\\ldots,x_n\\}\\subset\\mathbb{R}$, totally ordered by $\\le$.\n",
    "\n",
    "If $\\rho\\ge 0$, so that positive autocorrelation holds, then $P$ is monotone increasing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb7ae7a-2008-43bb-9ef3-1c85cd1362b2",
   "metadata": {},
   "source": [
    "## Geometric Sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6f36d-d210-4c4d-8d5d-41a04a6a5a2f",
   "metadata": {},
   "source": [
    "Consider a conditional mathematical expectation of a discounted sum of future measurements:\n",
    "\n",
    "$$\n",
    "v(x):= \\mathbb{E}_x\\sum_{t=0}^\\infty\\beta^t h(X_t):= \\mathbb{E}\\left[\\sum_{t=0}^\\infty \\beta^t h(X_t)|X_0=x\\right]\n",
    "$$\n",
    "\n",
    "for some constant $\\beta\\in\\mathbb{R}_+$ and $h\\in\\mathbb{R}^X$.\n",
    "\n",
    "- $(X_t)$ is $P$-Markov on some finite set $X$\n",
    "- $v(x)$ is **lifetime reward starting from state $x$**\n",
    "- $\\mathbb{E}_x$ indicates that we are conditioning on $X_0=x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9b3145-6f66-42c8-9820-17072234ab46",
   "metadata": {},
   "source": [
    "### Application: Valuation of Firms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ab9c6-3723-4cfe-91e2-e156124c9788",
   "metadata": {},
   "source": [
    "A firm receives random profit stream $(\\pi_t)_{t\\ge 0}$, total valuation (EPV) is\n",
    "\n",
    "$$\n",
    "V_0 = \\mathbb{E}\\sum_{t=0}^\\infty \\beta^t\\pi_t\n",
    "$$\n",
    "\n",
    "##### Common strategy\n",
    "\n",
    "- set $\\pi_t = \\pi(X_t)$ for some fixed $\\pi\\in\\mathbb{R}^X$, where $(X_t)_{t\\ge 0}$ is the state process\n",
    "- For known dynamics of $(X_t)$ and function $\\pi$, we can compute $V_0$\n",
    "\n",
    "Here we assume $(X_t)$ is $P$-Markov for $P\\in\\mathscr{M}(\\mathbb{R}^X)$ with finite $X$.\n",
    "\n",
    "THen conditioning on $X_0 = x$, we can write the values as\n",
    "\n",
    "$$\n",
    "v(x):=\\mathbb{E}_x \\sum_{t=0}^\\infty \\beta^t\\pi_t := \\mathbb{E}\\left[\\sum_{t=0}^\\infty \\beta^t \\pi_t | X_0=x\\right]\n",
    "$$\n",
    "\n",
    "By lemma 3.2.1, the value $v(x)$ is finite and the function $v\\in\\mathbb{R}^X$ can be obtained by\n",
    "\n",
    "$$\n",
    "v = \\sum_{t=0}^\\infty \\beta^tP^t\\pi = (I-\\beta P)^{-1} \\pi\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8fc15-9477-44e2-ae55-a9af630dacb0",
   "metadata": {},
   "source": [
    "### Application: Valuing consumption streams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad89a72e-a21e-48e9-8df5-c3189f8250ca",
   "metadata": {},
   "source": [
    "To model consumption-saving choices, we want to evaluate different consumption paths, where a **consumption path** is a nonnegative random sequence $(C_t)_{t\\ge 0}$.\n",
    "\n",
    "We consider consumption paths such that \n",
    "\n",
    "$$\n",
    "C_t = c(X_t),\\,\\,\\forall t\\ge 0, c\\in \\mathbb{R}_+^X\n",
    "$$\n",
    "\n",
    "and $(X_t)$ is $P$-Markov on finite set $X$.\n",
    "\n",
    "Thus, **consumption streams are time-invariant functions of a finite state Markov Chain**.\n",
    "\n",
    "In standard 'time additive' model of consumption preferences with constant geometric discounting, the time zero value of a consumption stream $(C_t)_{t\\ge 0}$ given current state $X_0=x\\in X$ is\n",
    "\n",
    "$$\n",
    "v(x) = \\mathbb{E}_x \\sum_{t=0}^\\infty \\beta^t u(C_t)\n",
    "$$\n",
    "\n",
    "and $u:\\mathbb{R}_+ \\mapsto \\mathbb{R}$ is called the **flow utility function**.\n",
    "\n",
    "\n",
    "**Dependence of $v(x)$ on $x$ comes from the inital condition $X_0=x$ influencing the Markov state process and therefore, the consumption path**.\n",
    "\n",
    "Using $C_t = c(X_t)$ and defining $r:=u\\circ c$ we can write,\n",
    "\n",
    "$$\n",
    "v(x) = \\mathbb{E}_x\\sum_{t=0}^\\infty \\beta^t r(X_t)\n",
    "$$\n",
    "\n",
    "By lemma 3.2.1, we have, under finite state space $X$,\n",
    "\n",
    "$$\n",
    "v= (I-\\beta P)^{-1}r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06ee99c-ff8b-4682-9f83-0ac78e4b7b43",
   "metadata": {},
   "source": [
    "#### CRRA example\n",
    "\n",
    "We have,\n",
    "\n",
    "$$\n",
    "u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma} \\tag{$c\\ge 0, \\gamma>0$}\n",
    "$$\n",
    "\n",
    "while $c(x)=\\exp(x)$, so that consumption takes the form\n",
    "\n",
    "$$\n",
    "C_t = \\exp(X_t)\n",
    "$$\n",
    "\n",
    "and $X_t$ is th Tauchen discretization of\n",
    "\n",
    "$$\n",
    "X_{t+1} = \\rho X_t + \\nu W_{t+1} \n",
    "$$\n",
    "\n",
    "where $W_{t+1}$ is IID and standard normal.\n",
    "\n",
    "Parameters are $n=25, \\beta =0.98, \\rho =0.96, \\nu =0.05, \\gamma =2$.\n",
    "\n",
    "We set $r=u\\circ c$ and solve for $v$ via \n",
    "\n",
    "$$\n",
    "v= (I-\\beta P)^{-1} r\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f133dc-5735-49b5-9cdd-51f8b39f6a5f",
   "metadata": {},
   "source": [
    "## Job Search Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d1f1b8-2b6b-4859-8b06-9176e7b27258",
   "metadata": {},
   "source": [
    "- **Extend the job search problem to a setting with Markov wage offer**.\n",
    "\n",
    "- **Discuss additional structure when the Markov operator for wage offers is monotone increasing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febd20b-00e1-4896-8589-2a966b3e0f16",
   "metadata": {},
   "source": [
    "### Job search with Markov State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f24cb-abfd-4f31-aa17-8c515e9d7966",
   "metadata": {},
   "source": [
    "We adopt the job search setting but assume\n",
    "\n",
    "- the wage process $(W_t)$ is $P$-Markov on $W\\subset \\mathbb{R}_+$\n",
    "- $P\\in \\mathscr{M}(\\mathbb{R}^W)$\n",
    "- $W$ is finite\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3d602-196a-4dd9-ac87-6e1cb5c249ee",
   "metadata": {},
   "source": [
    "#### Value Function Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fe1b0f-44ef-46f1-99b8-d53498e65873",
   "metadata": {},
   "source": [
    "The **value function** $v^*$ for the Markov job search model is now defined as:\n",
    "\n",
    "$v^*(w)$ is the maximum lifetime value that can be obtained **when the worker is unemployed** with current wage offer $w$ in hand.\n",
    "\n",
    "\n",
    "**Value function $v^*$ satisfies Bellman equation**\n",
    "\n",
    "$$\n",
    "v^*(w)=\\max\\left\\{\\frac{w}{1-\\beta}, c+\\beta\\sum_{w'\\in W}v^*(w')P(w,w')\\right\\}\n",
    "$$\n",
    "\n",
    "for all $w\\in W$, $c>0, \\beta\\in(0,1)$.\n",
    "\n",
    "**The corresponding Bellman Operator** is\n",
    "\n",
    "$$\n",
    "(Tv)(w)=\\max\\left\\{\\frac{w}{1-\\beta}, c+\\beta\\sum_{w'\\in W}v(w')P(w,w')\\right\\}\n",
    "$$\n",
    "\n",
    "**T is constructed so that $v^*$ is a fixed point**.\n",
    "\n",
    "A policy $\\sigma:W\\mapsto \\{0,1\\}$ is called **v-greedy** if\n",
    "\n",
    "$$\n",
    "\\sigma(w) = \\mathbb{1}\\left\\{\\frac{w'}{1-\\beta}\\ge c+\\beta\\sum_{w'\\in W}v(w')P(w,w')\\right\\}\n",
    "$$\n",
    "\n",
    "for all $w\\in W$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b9c6e-c407-4abe-a8fc-18f666e6928e",
   "metadata": {},
   "source": [
    "Let $V:=\\mathbb{R}_+^W$ and endow $V$ with the pointwise partial order $\\le$ and the supremum norm, so that\n",
    "\n",
    "$$\n",
    "\\|f-g\\|_{\\infty} = \\max_{w\\in W}\\|f(w)-g(w)\\|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ffcf2-669d-417e-96e3-46953d6c1201",
   "metadata": {},
   "source": [
    "### Recommended Study of the Proof of this Lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb56bf-b693-45c8-8e11-294ffe7bff1c",
   "metadata": {},
   "source": [
    "**Lemma 3.3.1.**\n",
    "\n",
    "$v^*$ is increasing on $(W,\\le)$ whenever $P$ is monotone increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18ff4d-7bf2-42fa-a25f-c51bd81c9aa1",
   "metadata": {},
   "source": [
    "**Proof**\n",
    "\n",
    "Let $iV$ set be the increasing functions in $V$ and suppose that $P$ is monotine increasing.\n",
    "\n",
    "$T$ is a self-map on $iV$ in this setting, since $v\\in iV$ implies $h(w):= c+\\beta\\sum_{w'}v(w')P(w,w')$ is in $iV$,\n",
    "\n",
    "Hence, for such a $v$, both $h$ and the stopping value function \n",
    "\n",
    "$$\n",
    "e(w):= \\frac{w}{1-\\beta}\n",
    "$$\n",
    "\n",
    "are in $iV$. It follows that $Tv=h\\vee e$ is in $iV$.\n",
    "\n",
    "Since $iV$ is a closed subset of $V$ and $T$ is a self-map on $iV$, the fixed point $v^*$ is in $iV$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2dd178-ff54-4c30-8aa3-ab11ed8d397b",
   "metadata": {},
   "source": [
    "### Continuation values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da94c72-d4f3-4f91-b655-f6d5ed336cd2",
   "metadata": {},
   "source": [
    "The continuation value $h^*$ from the IID case is now replaced by a **continuation value function**\n",
    "\n",
    "$$\n",
    "h^*(x) := c+\\beta \\sum_{w'}v^*(w')P(w,w')\\tag{$(w\\in W)$}\n",
    "$$\n",
    "\n",
    "**The continuation value function depends on $w$  because the current offer helps predict the offer next period, which in turn affects the value of cotinuting**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61203f-48b0-42c6-87a4-6bdadd8083bb",
   "metadata": {},
   "source": [
    "### Alternative way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f084e23-cf2a-4be4-8f65-40182bdd166e",
   "metadata": {},
   "source": [
    "Let $Q$ be the operator on $V$ defined at $h\\in V$ by\n",
    "\n",
    "$$\n",
    "(Qh)(w):= c+\\beta\\sum_{w'}\\max\\left\\{\\frac{w'}{1-\\beta}, h(w')\\right\\}P(w,w')\n",
    "$$\n",
    "\n",
    "for all $w\\in W$.\n",
    "\n",
    "Then we have, $Q$ is a order-preserving, self-map on $V$ and it is a contraction with modulus $\\beta$.\n",
    "\n",
    "We can iterate with $Q$ to obtain the continuation value function $h^*$ and then use the policy:\n",
    "\n",
    "$$\n",
    "\\sigma^*(w)=\\mathbb{1}\\left\\{\\frac{w'}{1-\\beta}\\ge h^*(w)\\right\\}\n",
    "$$\n",
    "\n",
    "that tells the worker to accept when the current stopping value exceeds the current continuation value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705c6275-be28-414f-971e-62d24884b2d3",
   "metadata": {},
   "source": [
    "## Job Search with Separation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b24b9-a8e9-4d1f-b7a0-d97cdaec2207",
   "metadata": {},
   "source": [
    "**Separation: An existing match between worker and firm terminates with probability $\\alpha$ every period.**\n",
    "\n",
    "**Workers now views the loss of job as a capital loss and a spell of unemployment as an investment**.\n",
    "\n",
    "**For unemployed workers**, the value function satisfies the recursion:\n",
    "\n",
    "$$\n",
    "v_u^*(w) =\\max\\left\\{v_e^*{w}, c+\\beta\\sum_{w'\\in W} v_u^*(w')P(w,w')\\right\\} \\tag{1}\n",
    "$$\n",
    "\n",
    "where $v_e^*$ is the value function for an employed worker, i.e., the lifetime value of a worker who starts the period employed at wage $w$.\n",
    "\n",
    "Value function $v_e^*$ satisfies:\n",
    "\n",
    "$$\n",
    "v_e^*(w) = w +\\beta\\left[\\alpha\\sum_{w'\\in W} v_u^*(w')P(w,w')+(1-\\alpha) v_e^*(w)\\right] \\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef871303-2256-4189-86cc-78a1764b1ba2",
   "metadata": {},
   "source": [
    "**We claim that**\n",
    "\n",
    "When $0<\\alpha,\\beta<1$, this system has a unique solution $(v_e^*,v_u^*)\\in V\\times V$.\n",
    "\n",
    "To show this, we first solve $(2)$ in terms of $v_e^*$ to obtain\n",
    "\n",
    "$$\n",
    "v_e^*(w) = \\frac{1}{1-\\beta(1-\\alpha)}(w+\\alpha\\beta(Pv^*_u)(w))\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "(Pv^*_u)(w) = \\sum_{w'\\in W} v^*_u(w')P(w,w')\n",
    "$$\n",
    "\n",
    "Substitute it into $(1)$ gives,\n",
    "\n",
    "$$\n",
    "v_u^*(w)=\\max\\left\\{\\frac{1}{1-\\beta(1-\\alpha)}(w+\\alpha\\beta(Pv^*_u)(w)), c+\\beta(Pv_u^*)(w)\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0979028-a1e5-4518-a156-783530b362e8",
   "metadata": {},
   "source": [
    "The stopping value function is\n",
    "\n",
    "$$\n",
    "s^*(w):=\\frac{1}{1-\\beta(1-\\alpha)}(w+\\alpha\\beta(Pu_v^*(w))\n",
    "$$\n",
    "\n",
    "and continuation value function is\n",
    "\n",
    "$$\n",
    "h_e^*(w) = c+\\beta(Pv_u^*)(w)\n",
    "$$\n",
    "\n",
    "The value function is the pointwise maximum, i.e.,\n",
    "\n",
    "$$\n",
    "v_u^* = s^*\\vee h_e^*\n",
    "$$\n",
    "\n",
    "The worker's optimal policy while unemployed is\n",
    "\n",
    "$$\n",
    "\\sigma^*(w) = \\mathbb{1}\\{s^*(w)\\ge h^*(w)\\}\n",
    "$$\n",
    "\n",
    "The smallest $w\\in W$ such that $\\sigma^*(w)=1$ is called the **reservation wage**.\n",
    "\n",
    "**The reservation wage falls with $\\alpha$ since time spent unemployed is a capital investment in better wages, and the value of this investment declines as the separation rate rises.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403a66e-e746-4bf0-8449-cd55460cafdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
