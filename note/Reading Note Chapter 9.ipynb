{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136566d8-983a-4b4c-9cf5-312b75449b74",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e125e-b774-42a2-ae63-7956a5c2bc7e",
   "metadata": {},
   "source": [
    "### Order stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155019c-09db-4942-8a54-9f37355e25c4",
   "metadata": {},
   "source": [
    "Let $V$ be a partially ordered set and let $T$ be a self-map on $V$ with **exactly one fixed point** $\\bar v\\in V$.\n",
    "\n",
    "We call \n",
    "\n",
    "- $T$ is **upward stable** on $V$ if $v\\in V$ and $v\\precsim Tv \\implies v\\precsim \\bar v$\n",
    "\n",
    "- $T$ is **downward stable** on $V$ if $v\\in V, Tv\\precsim v \\implies \\bar v \\precsim v$.\n",
    "\n",
    "- $T$ is **order stable** on $V$ if $T$ is both upward and downward stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b6c88-ca76-473e-b9f6-eead3daf53a9",
   "metadata": {},
   "source": [
    "### Lemma 9.1.1.T is order-preserving+Globally stable $\\implies$ T is order-stable\n",
    "\n",
    "Let $X$ be finite, let $V$ be a subset of $\\mathbb{R}^X$, and let $T$ be an order-preserving self-map on $V$.\n",
    "\n",
    "If $T$ is globally stable on $V$, then $T$ is order stable on $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3d5ac8-0e54-426a-a7a3-c84c05733920",
   "metadata": {},
   "source": [
    "### Order duals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c69b90-2fd9-45e6-b94a-4c913bc17670",
   "metadata": {},
   "source": [
    "Given partially ordered set $V$, let $V^\\partial = (V, \\precsim^\\partial)$ be the **order dual**, so that, for $u,v\\in V$, we have $u\\precsim^\\partial v$ if and only if $v\\precsim u$.\n",
    "\n",
    "(The order dual $V^\\partial$ is just $V$ with the order reversed.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef071a-ce32-43c1-8cfa-0ea4ba1ec6c0",
   "metadata": {},
   "source": [
    "### Lemma 9.1.2. $S$ is order-stable on $V$ $\\iff$ $S$ is order-stable on $V^\\partial$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee53ed6-96aa-4106-8fbc-506db65a577f",
   "metadata": {},
   "source": [
    "## Abstract Dynamic Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f9106-9f6a-4090-a388-8fc597301af8",
   "metadata": {},
   "source": [
    "An **abstract dynamic program (ADP)** is a pair $\\mathcal{A} = (V, \\{T_\\sigma\\}_{\\sigma\\in\\Sigma})$ such that \n",
    "\n",
    "1. $V = (V,\\precsim)$ is a partially ordered set,\n",
    "2. $\\{T_\\sigma\\}:= \\{T_\\sigma\\}_{\\sigma\\in\\Sigma}$ is a family of self-maps on $V$\n",
    "3. for all $v\\in V$, the set $\\{T_\\sigma v\\}_{\\sigma\\in\\Sigma}$ has both a least and greatest element.\n",
    "\n",
    "- Elements of the index set $\\Sigma$ are called **policies**\n",
    "- Elements of $\\{T_\\sigma\\}$ are called **policy operators**\n",
    "- Given $v\\in V$, a policy $\\sigma\\in\\Sigma$ is called **v-greedy** if $T_\\tau v\\precsim T_\\sigma v$ for all $\\tau\\in\\Sigma$.\n",
    "\n",
    "Existence of greastest element in III of the definition is equivalent to the statement that **each $v\\in V$ has at least one v-greedy policy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6568e25-3735-4d5f-ad62-51211d1992f8",
   "metadata": {},
   "source": [
    "### Example of ADP that cannot be represented as RDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82acd228-4dbd-4d88-99c4-c0dc6f85a928",
   "metadata": {},
   "source": [
    "Recall the $Q$-factor MDP Bellman operator, which takes the form\n",
    "\n",
    "$$\n",
    "(Sq)(x,a) = r(x,a)+\\beta\\sum_{x'}\\max_{a\\in\\Gamma(x')} q(x',a') P(x,a,x')\n",
    "$$\n",
    "\n",
    "with $q\\in\\mathbb{R}^G$ and $(x,a)\\in G$.\n",
    "\n",
    "The $Q$-factor policy operators $\\{S_\\sigma\\}$ are given by\n",
    "\n",
    "$$\n",
    "(S_\\sigma q)(x,a) = r(x,a) + \\beta\\sum_{x'}q(x', \\sigma(x'))P(x,a,x')\n",
    "$$\n",
    "\n",
    "Each $S_\\sigma$ is a self-map on $\\mathbb{R}^G = (\\mathbb{R}^G, \\le)$.\n",
    "\n",
    "If $q\\in\\mathbb{R}^G$ and $\\sigma\\in\\Sigma$ is such that $\\sigma(x)\\in \\arg\\max_{a\\in\\Gamma(x)}q(x,a)$ for all $x\\in X$, then $S_\\sigma q\\ge S_\\tau q$ for all $\\tau \\in\\Sigma$.\n",
    "\n",
    "Hence $\\sigma$ is the $q$-greedy policy and $\\mathcal{A}=(\\mathbb{R}^G,\\{S_\\sigma\\})$ is an ADP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a271c82e-1003-488a-ab69-22e9304e47a3",
   "metadata": {},
   "source": [
    "# Optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c055686-875c-446d-86c8-15668dd5ae06",
   "metadata": {},
   "source": [
    "## Max-optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ae559-1ca1-493c-abf4-840071a4a465",
   "metadata": {},
   "source": [
    "We call an ADP $\\mathcal{A} = (V,\\{T_\\sigma\\})$ **well-posed** if every policy operator $T_\\sigma$ has a unique fixed point in $V$. \n",
    "\n",
    "Well-posedness is a minimum requirement for constructing an optimality theory around ADP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1dbde2-dbbc-4c6c-9291-a7fb0a8e8d9f",
   "metadata": {},
   "source": [
    "#### Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f226a-4f54-4a7c-9a59-701cfa5b7122",
   "metadata": {},
   "source": [
    "Let $\\mathcal{A} = (V,\\{T_\\sigma\\})$ be an ADP. We set\n",
    "\n",
    "$$\n",
    "Tv = \\bigvee_\\sigma T_\\sigma v\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8cb50-96fa-45e0-953b-9822d7aa06a4",
   "metadata": {},
   "source": [
    "And call $T$ the **Bellman operator** generated by $\\mathcal{A}$. \n",
    "\n",
    "$T$ is well-defined self-map on $V$ by part III of the definition of ADP (the existence of greedy policy).\n",
    "\n",
    "A function $v\\in V$ is said to satisfy the **Bellman equation** if it is a fixed point of $T$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216bd4a-9e5c-46cb-9e30-f69f64fd2d5d",
   "metadata": {},
   "source": [
    "### Howard Operator\n",
    "\n",
    "Define a map $H$ from $V$ to $\\{v_\\sigma\\}$ via $Hv=v_\\sigma$ where $\\sigma$ is $v$-greedy.\n",
    "\n",
    "Iterating with $H$ generates the value sequence associated with Howard Policy Iteration.\n",
    "\n",
    "We call $H$ the **Howard operator generated by the ADP**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464ed77-e12e-4d14-9d54-52a7329d2d21",
   "metadata": {},
   "source": [
    "### Property of ADP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522e66f4-e12c-41bd-9413-506fe4e33001",
   "metadata": {},
   "source": [
    "Let $\\mathcal{A}: = (V, \\{T_\\sigma\\}_{\\sigma\\in\\Sigma})$ be an ADP.\n",
    "\n",
    "We call $\\mathcal{A}$\n",
    "\n",
    "- **finite** if $\\Sigma$ is a finite set.\n",
    "- **order stable** if every policy operator $T_\\sigma$ is order stable on $V$\n",
    "- **max-stable** if $A$ is order stable and $T$ has at least one fixed point in $V$.\n",
    "\n",
    "We have **max-stable $\\implies$ order-stable $\\implies$ well-posed**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2eac7-0363-47ef-a3d6-1a2981581825",
   "metadata": {},
   "source": [
    "### Proposition 9.2.1. Finite and order stable ADP is max-stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb7994-aaea-47d2-a8dd-67b2cef6d076",
   "metadata": {},
   "source": [
    "### Corollary 9.2.2. If RDP is globally stable, then the ADP generated by the RDP is max-stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f18897-1fb3-4faf-b946-ab251a8457d2",
   "metadata": {},
   "source": [
    "### Proposition 9.2.3. For ADP generated by RDP, Well-posed iff Order stable on an order interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73103e8c-a3d2-454b-a3f2-ba0126835371",
   "metadata": {},
   "source": [
    "## Max-Optimality Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e39c9-33ef-4509-8d62-517cf49a6e72",
   "metadata": {},
   "source": [
    "Let $\\mathcal{A} = (V, \\{T_\\sigma\\})$ be a well-posed ADP with $\\sigma$-value functions $\\{v_\\sigma\\}$.\n",
    "\n",
    "We define the set of value functions. \n",
    "\n",
    "$$\n",
    "V_\\Sigma = \\{v_\\sigma\\}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "V_u = \\{v\\in V: v\\precsim Tv\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e8244-4354-40d0-b25d-a360ddd015d0",
   "metadata": {},
   "source": [
    "If $V_\\Sigma$ has a greatest value, we denote it as $v^*$ and call it the **value function** generated by the ADP.\n",
    "\n",
    "A policy $\\sigma\\in\\Sigma$ is called **optimal** for the ADP if $v_\\sigma = v^*$.\n",
    "\n",
    "We say that the ADP obeys **Bellman's principle of optimality** if\n",
    "\n",
    "$$\n",
    "\\sigma\\in\\Sigma \\text{ is optimal for the ADP $\\iff$ $\\sigma$ is $v^*$-greedy }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded5148-40bd-420a-bd16-0a38bdd7e0ea",
   "metadata": {},
   "source": [
    "### Lemma B.4.1. Properties of Order stable ADP\n",
    "\n",
    "1. $v\\in V_u \\implies v\\precsim Hv$\n",
    "\n",
    "**Proof:**\n",
    "$v\\in V_u \\implies v \\precsim Tv \\implies v\\precsim T_\\tau v$, $\\tau$ is $v$-greedy.\n",
    "\n",
    "Since $T_\\tau$ is order stable, we have \n",
    "\n",
    "\n",
    "2. $Tv_\\sigma = v_\\sigma\\implies v_\\sigma =v^* $\n",
    "\n",
    "3. $Hv=v \\implies v=v^*$\n",
    "\n",
    "4. Finite and Order stable ADP $\\implies \\exists v^*, Hv^*=v^*$, $\\forall v, H^k v \\to v^*$, with finite $k$.\n",
    "\n",
    "5. $H^{k+1}v=H^k v\\implies H^k v = v^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5a1ee-c24b-4fbb-a392-8f30dcf8860d",
   "metadata": {},
   "source": [
    "# Theorem 9.2.4. Max-Optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c3240f-85a8-47b6-8546-89b4f0fbc26d",
   "metadata": {},
   "source": [
    "If the ADP is **finite and order stable**, then\n",
    "\n",
    "1. the set of $\\sigma$-value functions $V_\\sigma$ has a greatest element $v^*$\n",
    "\n",
    "2. $v^*$ is the unique solution to the Bellman equation in $V$.\n",
    "\n",
    "3. ADP obeys the Bellman's principle of optimality\n",
    "\n",
    "4. ADP has at least one optimal policy\n",
    "\n",
    "5. HPI returns an exact optimal policy in finitely many steps.\n",
    "\n",
    "\n",
    "If the ADP is **max-stable**, we have 1-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163aec7-2a9e-4096-b741-077bef1c12b4",
   "metadata": {},
   "source": [
    "### Lemma 9.2.6. VFI starting from $\\sigma$-value functions converges to the value function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1188fbd6-f919-4453-b295-0f5e646b9b97",
   "metadata": {},
   "source": [
    "### Lemma 9.2.7. $W_m$ is order-preserving self map on $V_u$. $v\\in V_u\\implies Tv\\le W_m v\\le T^m  v$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbac70a-a5fb-4340-883c-54dd0522ca66",
   "metadata": {},
   "source": [
    "### Lemma 9.2.8. $T^kv_\\sigma \\le W^k_m v_\\sigma \\le T^{km}v_\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d3b05-9f4f-49c1-bd72-c516a9379b8e",
   "metadata": {},
   "source": [
    "### Lemma 9.2.9. $W^{k+1}_m v_\\sigma = W^{k}_m v_\\sigma\\implies v^*= W^k_m v_\\sigma$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
